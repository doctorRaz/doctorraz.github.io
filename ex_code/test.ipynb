{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from requests) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from beautifulsoup4) (4.13.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pip in /Users/iseunghun/.pyenv/versions/3.13.0/lib/python3.13/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Using cached pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Using cached pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-25.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# arXiv 검색 페이지 URL 설정\n",
    "query = \"LLM\"\n",
    "url = f\"https://arxiv.org/search/?query={query}&searchtype=all&source=header&start=0\"\n",
    "\n",
    "# User-Agent 설정 (웹사이트 차단 방지)\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# 페이지 요청\n",
    "response = requests.get(url, headers=headers)\n",
    "print(f\"Status Code: {response.status_code}\")  # 200이면 성공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\"/>\n",
      "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/>\n",
      "<!-- new favicon config and versions by realfavicongenerator.net -->\n",
      "<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png\">\n",
      "<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png\">\n",
      "<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png\">\n",
      "<link rel=\"manifest\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest\">\n",
      "<link rel=\"mask-icon\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg\" color=\"#b31b1b\">\n",
      "<link rel=\"shortcut icon\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico\">\n",
      "<meta name=\"msapplication-TileColor\" content=\"#b31b1b\">\n",
      "<meta name=\"msapplication-config\" content=\"images/icons/browserconfig.xml\">\n",
      "<meta name=\"theme-color\" content=\"#b31b1b\">\n",
      "<!-- end favicon config -->\n",
      "<title>Search | arXiv e-print repository</title>\n",
      "<script defer src=\"https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js\"></script>\n",
      "<link rel=\"stylesheet\" href=\"https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css\" />\n",
      "<script type=\"text/x-mathjax-config\">\n",
      "  MathJax.Hub.Config({\n",
      "    messageStyle: \"none\",\n",
      "    extensions: [\"tex2jax.js\"],\n",
      "    jax: [\"input/TeX\", \"output/HTML-CSS\"],\n",
      "    tex2jax: {\n",
      "      inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
      "      displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ],\n",
      "      processEscapes: true,\n",
      "      ignoreClass: '.*',\n",
      "      processClass: 'mathjax.*'\n",
      "    },\n",
      "    TeX: {\n",
      "        extensions: [\"AMSmath.js\", \"AMSsymbols.js\", \"noErrors.js\"],\n",
      "        noErrors: {\n",
      "          inlineDelimiters: [\"$\",\"$\"],\n",
      "          multiLine: false,\n",
      "          style: {\n",
      "            \"font-size\": \"normal\",\n",
      "            \"border\": \"\"\n",
      "          }\n",
      "        }\n",
      "    },\n",
      "    \"HTML-CSS\": { availableFonts: [\"TeX\"] }\n",
      "  });\n",
      "</script>\n",
      "<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>\n",
      "<script src=\"https://static.arxiv.org/static/base/1.0.0a5/js/notification.js\"></script>\n",
      "\n",
      "    \n",
      "  <link rel=\"stylesheet\" href=\"https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css\" />\n",
      "  <link rel=\"stylesheet\" href=\"https://static.arxiv.org/static/search/0.5.6/css/search.css\" />\n",
      "  <script\n",
      "    src=\"https://code.jquery.com/jquery-3.2.1.slim.min.js\"\n",
      "    integrity=\"sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g=\"\n",
      "    crossorigin=\"anonymous\"></script>\n",
      "\n",
      "  <script src=\"https://static.arxiv.org/static/search/0.5.6/js/fieldset.js\"></script>\n",
      "  <style>\n",
      "  radio#cf-customfield_11400 {\n",
      "    display: none;\n",
      "  }\n",
      "  </style>\n",
      "\n",
      "  </head>\n",
      "  <body>\n",
      "  \n",
      "  \n",
      "  <header><a href=\"#main-container\" class=\"is-sr-only\">Skip to main content</a>\n",
      "    \n",
      "    <!-- contains Cornell logo and sponsor statement -->\n",
      "<div class=\"attribution level is-marginless\" role=\"banner\">\n",
      "  <div class=\"level-left\">\n",
      "    <a class=\"level-item\" href=\"https://cornell.edu/\"><img src=\"https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg\" alt=\"Cornell University\" width=\"200\" aria-label=\"logo\" /></a>\n",
      "  </div>\n",
      "  <div class=\"level-right is-marginless\"><p class=\"sponsors level-item is-marginless\"><span id=\"support-ack-url\">We gratefully acknowledge support from<br /> the Simons Foundation, <a href=\"https://info.arxiv.org/about/ourmembers.html\">member institutions</a>, and all contributors. <a href=\"https://info.arxiv.org/about/donate.html\">Donate</a></span></p></div>\n",
      "</div>\n",
      "<!-- contains arXiv identity and search bar -->\n",
      "<div class=\"identity level is-marginless\">\n",
      "  <div class=\"level-left\">\n",
      "    <div class=\"level-item\">\n",
      "      <a class=\"arxiv\" href=\"https://arxiv.org/\" aria-label=\"arxiv-logo\">\n",
      "        <img src=\"https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg\" aria-label=\"logo\" alt=\"arxiv logo\" width=\"85\" style=\"width:85px;\"/>\n",
      "      </a>\n",
      "    </div>\n",
      "  </div>\n",
      "  \n",
      "  <div class=\"search-block level-right\">\n",
      "    <form class=\"level-item mini-search\" method=\"GET\" action=\"https://arxiv.org/search\">\n",
      "      <div class=\"field has-addons\">\n",
      "        <div class=\"control\">\n",
      "          <input class=\"input is-small\" type=\"text\" name=\"query\" placeholder=\"Search...\" aria-label=\"Search term or terms\" />\n",
      "          <p class=\"help\"><a href=\"https://info.arxiv.org/help\">Help</a> | <a href=\"https://arxiv.org/search/advanced\">Advanced Search</a></p>\n",
      "        </div>\n",
      "        <div class=\"control\">\n",
      "          <div class=\"select is-small\">\n",
      "            <select name=\"searchtype\" aria-label=\"Field to search\">\n",
      "              <option value=\"all\" selected=\"selected\">All fields</option>\n",
      "              <option value=\"title\">Title</option>\n",
      "              <option value=\"author\">Author</option>\n",
      "              <option value=\"abstract\">Abstract</option>\n",
      "              <option value=\"comments\">Comments</option>\n",
      "              <option value=\"journal_ref\">Journal reference</option>\n",
      "              <option value=\"acm_class\">ACM classification</option>\n",
      "              <option value=\"msc_class\">MSC classification</option>\n",
      "              <option value=\"report_num\">Report number</option>\n",
      "              <option value=\"paper_id\">arXiv identifier</option>\n",
      "              <option value=\"doi\">DOI</option>\n",
      "              <option value=\"orcid\">ORCID</option>\n",
      "              <option value=\"author_id\">arXiv author ID</option>\n",
      "              <option value=\"help\">Help pages</option>\n",
      "              <option value=\"full_text\">Full text</option>\n",
      "            </select>\n",
      "          </div>\n",
      "        </div>\n",
      "        <input type=\"hidden\" name=\"source\" value=\"header\">\n",
      "        <button class=\"button is-small is-cul-darker\">Search</button>\n",
      "      </div>\n",
      "    </form>\n",
      "  </div>\n",
      "</div> <!-- closes identity -->\n",
      "\n",
      "<div class=\"container\">\n",
      "    <div class=\"user-tools is-size-7 has-text-right has-text-weight-bold\" role=\"navigation\" aria-label=\"User menu\">\n",
      "      <a href=\"https://arxiv.org/login\">Login</a>\n",
      "    </div>\n",
      "</div>\n",
      "    \n",
      "  </header>\n",
      "  <main class=\"container\" id=\"main-container\">\n",
      "    \n",
      "\n",
      "\n",
      "    \n",
      "  <div class=\"level is-marginless\">\n",
      "    <div class=\"level-left\">\n",
      "      <h1 class=\"title is-clearfix\">\n",
      "    \n",
      "        Showing 1&ndash;50 of 30,039 results for all: <span class=\"mathjax\">LLM</span>\n",
      "    \n",
      "</h1>\n",
      "    </div>\n",
      "    <div class=\"level-right is-hidden-mobile\">\n",
      "      <!-- feedback for mobile is moved to footer -->\n",
      "      <span class=\"help\" style=\"display: inline-block;\"><a href=\"https://github.com/arXiv/arxiv-search/releases\">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>\n",
      "    </div>\n",
      "  </div>\n",
      "    <div class=\"content\">\n",
      "      \n",
      "  <form method=\"GET\" action=\"/search/\"  aria-role=\"search\">\n",
      "    \n",
      "\n",
      "    \n",
      "    <div class=\"field has-addons-tablet\">\n",
      "      <div class=\"control is-expanded\">\n",
      "        <label for=\"query\" class=\"hidden-label\">Search term or terms</label>\n",
      "        \n",
      "          <input class=\"input is-medium\" id=\"query\" name=\"query\" placeholder=\"Search term...\" type=\"text\" value=\"LLM\">\n",
      "        \n",
      "        \n",
      "      </div>\n",
      "      <div class=\"select control is-medium\">\n",
      "        <label class=\"is-hidden\" for=\"searchtype\">Field</label>\n",
      "        <select class=\"is-medium\" id=\"searchtype\" name=\"searchtype\"><option selected value=\"all\">All fields</option><option value=\"title\">Title</option><option value=\"author\">Author(s)</option><option value=\"abstract\">Abstract</option><option value=\"comments\">Comments</option><option value=\"journal_ref\">Journal reference</option><option value=\"acm_class\">ACM classification</option><option value=\"msc_class\">MSC classification</option><option value=\"report_num\">Report number</option><option value=\"paper_id\">arXiv identifier</option><option value=\"doi\">DOI</option><option value=\"orcid\">ORCID</option><option value=\"license\">License (URI)</option><option value=\"author_id\">arXiv author ID</option><option value=\"help\">Help pages</option><option value=\"full_text\">Full text</option></select>\n",
      "      </div>\n",
      "      <div class=\"control\">\n",
      "          <button class=\"button is-link is-medium\">Search</button>\n",
      "      </div>\n",
      "    </div>\n",
      "    <div class=\"field\">\n",
      "      <div class=\"control is-size-7\">\n",
      "        \n",
      "        <label class=\"radio\">\n",
      "          <input checked id=\"abstracts-0\" name=\"abstracts\" type=\"radio\" value=\"show\"> Show abstracts\n",
      "        </label>\n",
      "        \n",
      "        <label class=\"radio\">\n",
      "          <input id=\"abstracts-1\" name=\"abstracts\" type=\"radio\" value=\"hide\"> Hide abstracts\n",
      "        </label>\n",
      "        \n",
      "      </div>\n",
      "    </div>\n",
      "    <div class=\"is-clearfix\" style=\"height: 2.5em\"> \n",
      "      <div class=\"is-pulled-right\">\n",
      "        \n",
      "        <a href=\"/search/advanced?terms-0-term=LLM&amp;terms-0-field=all&amp;size=50&amp;order=-announced_date_first\">Advanced Search</a>\n",
      "        \n",
      "      </div>\n",
      "    </div>\n",
      "    <input type=\"hidden\" name=\"order\" value=\"-announced_date_first\">\n",
      "    <input type=\"hidden\" name=\"size\" value=\"50\">\n",
      "  </form>\n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "      \n",
      "<div class=\"level breathe-horizontal\">\n",
      "  <div class=\"level-left\">\n",
      "    <form method=\"GET\" action=\"/search/\">\n",
      "      <div style=\"display: none;\">\n",
      "        \n",
      "          \n",
      "            <select id=\"searchtype\" name=\"searchtype\"><option selected value=\"all\">All fields</option><option value=\"title\">Title</option><option value=\"author\">Author(s)</option><option value=\"abstract\">Abstract</option><option value=\"comments\">Comments</option><option value=\"journal_ref\">Journal reference</option><option value=\"acm_class\">ACM classification</option><option value=\"msc_class\">MSC classification</option><option value=\"report_num\">Report number</option><option value=\"paper_id\">arXiv identifier</option><option value=\"doi\">DOI</option><option value=\"orcid\">ORCID</option><option value=\"license\">License (URI)</option><option value=\"author_id\">arXiv author ID</option><option value=\"help\">Help pages</option><option value=\"full_text\">Full text</option></select>\n",
      "          \n",
      "        \n",
      "          \n",
      "            <input id=\"query\" name=\"query\" type=\"text\" value=\"LLM\">\n",
      "          \n",
      "        \n",
      "          \n",
      "        \n",
      "          \n",
      "        \n",
      "          \n",
      "            <ul id=\"abstracts\"><li><input checked id=\"abstracts-0\" name=\"abstracts\" type=\"radio\" value=\"show\"> <label for=\"abstracts-0\">Show abstracts</label></li><li><input id=\"abstracts-1\" name=\"abstracts\" type=\"radio\" value=\"hide\"> <label for=\"abstracts-1\">Hide abstracts</label></li></ul>\n",
      "          \n",
      "        \n",
      "      </div>\n",
      "      <div class=\"box field is-grouped is-grouped-multiline level-item\">\n",
      "        <div class=\"control\">\n",
      "          <span class=\"select is-small\">\n",
      "            <select id=\"size\" name=\"size\"><option value=\"25\">25</option><option selected value=\"50\">50</option><option value=\"100\">100</option><option value=\"200\">200</option></select>\n",
      "          </span>\n",
      "          <label for=\"size\">results per page</label>.\n",
      "        </div>\n",
      "        <div class=\"control\">\n",
      "          <label for=\"order\">Sort results by</label>\n",
      "          <span class=\"select is-small\">\n",
      "            <select id=\"order\" name=\"order\"><option selected value=\"-announced_date_first\">Announcement date (newest first)</option><option value=\"announced_date_first\">Announcement date (oldest first)</option><option value=\"-submitted_date\">Submission date (newest first)</option><option value=\"submitted_date\">Submission date (oldest first)</option><option value=\"\">Relevance</option></select>\n",
      "          </span>\n",
      "        </div>\n",
      "        <div class=\"control\">\n",
      "          <button class=\"button is-small is-link\">Go</button>\n",
      "        </div>\n",
      "      </div>\n",
      "    </form>\n",
      "  </div>\n",
      "</div>\n",
      "      \n",
      "\n",
      "\n",
      "  <nav class=\"pagination is-small is-centered breathe-horizontal\" role=\"navigation\" aria-label=\"pagination\">\n",
      "    \n",
      "    <a href=\"\"\n",
      "      class=\"pagination-previous is-invisible\">Previous\n",
      "    </a>\n",
      "    \n",
      "    \n",
      "      <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=50\"\n",
      "        class=\"pagination-next\" >Next\n",
      "      </a>\n",
      "    \n",
      "    <ul class=\"pagination-list\">\n",
      "\n",
      "      <li>\n",
      "        <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=0\"\n",
      "          class=\"pagination-link is-current\"\n",
      "          aria-label=\"Goto page 1\">1\n",
      "        </a>\n",
      "      </li>\n",
      "\n",
      "      \n",
      "                                     \n",
      "          \n",
      "          <li>\n",
      "            <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=50\"\n",
      "              class=\"pagination-link \"\n",
      "              aria-label=\"Page 2\"\n",
      "              aria-current=\"page\">2\n",
      "            </a>\n",
      "          </li>\n",
      "          \n",
      "          <li>\n",
      "            <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=100\"\n",
      "              class=\"pagination-link \"\n",
      "              aria-label=\"Page 3\"\n",
      "              aria-current=\"page\">3\n",
      "            </a>\n",
      "          </li>\n",
      "          \n",
      "          <li>\n",
      "            <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=150\"\n",
      "              class=\"pagination-link \"\n",
      "              aria-label=\"Page 4\"\n",
      "              aria-current=\"page\">4\n",
      "            </a>\n",
      "          </li>\n",
      "          \n",
      "          <li>\n",
      "            <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=200\"\n",
      "              class=\"pagination-link \"\n",
      "              aria-label=\"Page 5\"\n",
      "              aria-current=\"page\">5\n",
      "            </a>\n",
      "          </li>\n",
      "          \n",
      "          <li><span class=\"pagination-ellipsis\">&hellip;</span></li>\n",
      "        \n",
      "      \n",
      "    </ul>\n",
      "  </nav>\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "<ol class=\"breathe-horizontal\" start=\"1\"> \n",
      "\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06265\">arXiv:2504.06265</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06265\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06265\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        GOLLuM: Gaussian Process Optimized <span class=\"search-hit mathjax\">LLMs</span> -- Reframing <span class=\"search-hit mathjax\">LLM</span> Finetuning through Bayesian Optimization\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Rankovi%C4%87%2C+B\">Bojana Ranković</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Schwaller%2C+P\">Philippe Schwaller</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06265v1-abstract-short\" style=\"display: inline;\">\n",
      "        Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) can encode complex relationships in their latent spaces, yet harnessing them for optimization under uncertainty remains challenging. We address this gap with a novel architecture that reframes&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06265v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06265v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06265v1-abstract-full\" style=\"display: none;\">\n",
      "        Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) can encode complex relationships in their latent spaces, yet harnessing them for optimization under uncertainty remains challenging. We address this gap with a novel architecture that reframes <span class=\"search-hit mathjax\">LLM</span> finetuning as Gaussian process (GP) marginal likelihood optimization via deep kernel methods. We introduce <span class=\"search-hit mathjax\">LLM</span>-based deep kernels, jointly optimized with GPs to preserve the benefits of both - <span class=\"search-hit mathjax\">LLMs</span> to provide a rich and flexible input space for Bayesian optimization and - GPs to model this space with predictive uncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction optimization, our method nearly doubles the discovery rate of high-performing reactions compared to static <span class=\"search-hit mathjax\">LLM</span> embeddings (from 24% to 43% coverage of the top 5% reactions in just 50 optimization iterations). We also observe a 14% improvement over domain-specific representations without requiring specialized features. Extensive empirical evaluation across 19 benchmarks - ranging from general chemistry to reaction and molecular property optimization - demonstrates our method&#39;s robustness, generality, and consistent improvements across: (1) tasks, (2) <span class=\"search-hit mathjax\">LLM</span> architectures (encoder, decoder, encoder-decoder), (3) pretraining domains (chemistry-related or general-purpose) and (4) hyperparameter settings (tuned once on a single dataset). Finally, we explain these improvements: joint <span class=\"search-hit mathjax\">LLM</span>-GP optimization through marginal likelihood implicitly performs contrastive learning, aligning representations to produce (1) better-structured embedding spaces, (2) improved uncertainty calibration, and (3) more efficient sampling - without requiring any external loss. This work provides both practical advances in sample-efficient optimization and insights into what makes effective Bayesian optimization.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06265v1-abstract-full').style.display = 'none'; document.getElementById('2504.06265v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06261\">arXiv:2504.06261</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06261\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06261\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Hogwild! Inference: Parallel <span class=\"search-hit mathjax\">LLM</span> Generation via Concurrent Attention\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Rodionov%2C+G\">Gleb Rodionov</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Garipov%2C+R\">Roman Garipov</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Shutova%2C+A\">Alina Shutova</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Yakushev%2C+G\">George Yakushev</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Egiazarian%2C+V\">Vage Egiazarian</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Sinitsin%2C+A\">Anton Sinitsin</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Kuznedelev%2C+D\">Denis Kuznedelev</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Alistarh%2C+D\">Dan Alistarh</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06261v1-abstract-short\" style=\"display: inline;\">\n",
      "        Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) have demonstrated the ability to tackle increasingly complex tasks through advanced reasoning, long-form content generation, and tool use. Solving these tasks often involves long inference-time computations. In human problem solving, a common strategy to expedite work is collaboration: by dividing the problem into sub-tasks, expl&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06261v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06261v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06261v1-abstract-full\" style=\"display: none;\">\n",
      "        Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) have demonstrated the ability to tackle increasingly complex tasks through advanced reasoning, long-form content generation, and tool use. Solving these tasks often involves long inference-time computations. In human problem solving, a common strategy to expedite work is collaboration: by dividing the problem into sub-tasks, exploring different strategies concurrently, etc. Recent research has shown that <span class=\"search-hit mathjax\">LLMs</span> can also operate in parallel by implementing explicit cooperation frameworks, such as voting mechanisms or the explicit creation of independent sub-tasks that can be executed in parallel. However, each of these frameworks may not be suitable for all types of tasks, which can hinder their applicability. In this work, we propose a different design approach: we run <span class=\"search-hit mathjax\">LLM</span> &#34;workers&#34; in parallel , allowing them to synchronize via a concurrently-updated attention cache and prompt these workers to decide how best to collaborate. Our approach allows the instances to come up with their own collaboration strategy for the problem at hand, all the while &#34;seeing&#34; each other&#39;s partial progress in the concurrent cache. We implement this approach via Hogwild! Inference: a parallel <span class=\"search-hit mathjax\">LLM</span> inference engine where multiple instances of the same <span class=\"search-hit mathjax\">LLM</span> run in parallel with the same attention cache, with &#34;instant&#34; access to each other&#39;s generated tokens. Hogwild! inference takes advantage of Rotary Position Embeddings (RoPE) to avoid recomputation while improving parallel hardware utilization. We find that modern reasoning-capable <span class=\"search-hit mathjax\">LLMs</span> can perform inference with shared Key-Value cache out of the box, without additional fine-tuning.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06261v1-abstract-full').style.display = 'none'; document.getElementById('2504.06261v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">Preprint, work in progress</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06260\">arXiv:2504.06260</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06260\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06260\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Numerical Analysis\">math.NA</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        FEABench: Evaluating Language Models on Multiphysics Reasoning Ability\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Mudur%2C+N\">Nayantara Mudur</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Cui%2C+H\">Hao Cui</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Venugopalan%2C+S\">Subhashini Venugopalan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Raccuglia%2C+P\">Paul Raccuglia</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Brenner%2C+M+P\">Michael P. Brenner</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Norgaard%2C+P\">Peter Norgaard</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06260v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;to answer quantitative problems is an essential requirement in engineering and science. We present FEABench, a benchmark to evaluate the ability of large language models (<span class=\"search-hit mathjax\">LLMs</span>) and&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06260v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06260v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06260v1-abstract-full\" style=\"display: none;\">\n",
      "        Building precise simulations of the real world and invoking numerical solvers to answer quantitative problems is an essential requirement in engineering and science. We present FEABench, a benchmark to evaluate the ability of large language models (<span class=\"search-hit mathjax\">LLMs</span>) and <span class=\"search-hit mathjax\">LLM</span> agents to simulate and solve physics, mathematics and engineering problems using finite element analysis (FEA). We introduce a comprehensive evaluation scheme to investigate the ability of <span class=\"search-hit mathjax\">LLMs</span> to solve these problems end-to-end by reasoning over natural language problem descriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to compute the answers. We additionally design a language model agent equipped with the ability to interact with the software through its Application Programming Interface (API), examine its outputs and use tools to improve its solutions over multiple iterations. Our best performing strategy generates executable API calls 88% of the time. <span class=\"search-hit mathjax\">LLMs</span> that can successfully interact with and operate FEA software to solve problems such as those in our benchmark would push the frontiers of automation in engineering. Acquiring this capability would augment <span class=\"search-hit mathjax\">LLMs</span>&#39; reasoning skills with the precision of numerical solvers and advance the development of autonomous systems that can tackle complex problems in the real world. The code is available at https://github.com/google/feabench\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06260v1-abstract-full').style.display = 'none'; document.getElementById('2504.06260v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">39 pages. Accepted at the NeurIPS 2024 Workshops on Mathematical Reasoning and AI and Open-World Agents</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06256\">arXiv:2504.06256</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06256\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06256\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Transfer between Modalities with MetaQueries\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Pan%2C+X\">Xichen Pan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Shukla%2C+S+N\">Satya Narayan Shukla</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Singh%2C+A\">Aashu Singh</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhao%2C+Z\">Zhuokai Zhao</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Mishra%2C+S+K\">Shlok Kumar Mishra</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+J\">Jialiang Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Xu%2C+Z\">Zhiyang Xu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Chen%2C+J\">Jiuhai Chen</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Li%2C+K\">Kunpeng Li</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Juefei-Xu%2C+F\">Felix Juefei-Xu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Hou%2C+J\">Ji Hou</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Xie%2C+S\">Saining Xie</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06256v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;complex training recipes and careful data balancing. We introduce MetaQueries, a set of learnable queries that act as an efficient interface between autoregressive multimodal <span class=\"search-hit mathjax\">LLMs</span> (MLLMs) and diffusion models. MetaQueries connects the MLLM&#39;s latents to the diffusion decoder, enabling knowledge-augmented image generation by leveraging the MLLM&#39;s deep&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06256v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06256v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06256v1-abstract-full\" style=\"display: none;\">\n",
      "        Unified multimodal models aim to integrate understanding (text output) and generation (pixel output), but aligning these different modalities within a single architecture often demands complex training recipes and careful data balancing. We introduce MetaQueries, a set of learnable queries that act as an efficient interface between autoregressive multimodal <span class=\"search-hit mathjax\">LLMs</span> (MLLMs) and diffusion models. MetaQueries connects the MLLM&#39;s latents to the diffusion decoder, enabling knowledge-augmented image generation by leveraging the MLLM&#39;s deep understanding and reasoning capabilities. Our method simplifies training, requiring only paired image-caption data and standard diffusion objectives. Notably, this transfer is effective even when the MLLM backbone remains frozen, thereby preserving its state-of-the-art multimodal understanding capabilities while achieving strong generative performance. Additionally, our method is flexible and can be easily instruction-tuned for advanced applications such as image editing and subject-driven generation.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06256v1-abstract-full').style.display = 'none'; document.getElementById('2504.06256v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">Project Page: https://xichenpan.com/metaquery</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06227\">arXiv:2504.06227</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06227\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06227\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        LExT: Towards Evaluating Trustworthiness of Natural Language Explanations\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Shailya%2C+K\">Krithi Shailya</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Rajpal%2C+S\">Shreya Rajpal</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Krishnan%2C+G+S\">Gokul S Krishnan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ravindran%2C+B\">Balaraman Ravindran</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06227v1-abstract-short\" style=\"display: inline;\">\n",
      "        As Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) become increasingly integrated into high-stakes domains, there have been several approaches proposed toward generating natural language explanations. These explanations are crucial for enhancing the interpretability of a model, especially in sensitive domains like healthcare, where transparency and reliability are key. In ligh&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06227v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06227v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06227v1-abstract-full\" style=\"display: none;\">\n",
      "        As Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) become increasingly integrated into high-stakes domains, there have been several approaches proposed toward generating natural language explanations. These explanations are crucial for enhancing the interpretability of a model, especially in sensitive domains like healthcare, where transparency and reliability are key. In light of such explanations being generated by <span class=\"search-hit mathjax\">LLMs</span> and its known concerns, there is a growing need for robust evaluation frameworks to assess model-generated explanations. Natural Language Generation metrics like BLEU and ROUGE capture syntactic and semantic accuracies but overlook other crucial aspects such as factual accuracy, consistency, and faithfulness. To address this gap, we propose a general framework for quantifying trustworthiness of natural language explanations, balancing Plausibility and Faithfulness, to derive a comprehensive Language Explanation Trustworthiness Score (LExT) (The code and set up to reproduce our experiments are publicly available at https://github.com/cerai-iitm/LExT). Applying our domain-agnostic framework to the healthcare domain using public medical datasets, we evaluate six models, including domain-specific and general-purpose models. Our findings demonstrate significant differences in their ability to generate trustworthy explanations. On comparing these explanations, we make interesting observations such as inconsistencies in Faithfulness demonstrated by general-purpose models and their tendency to outperform domain-specific fine-tuned models. This work further highlights the importance of using a tailored evaluation framework to assess natural language explanations in sensitive fields, providing a foundation for improving the trustworthiness and transparency of language models in healthcare and beyond.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06227v1-abstract-full').style.display = 'none'; document.getElementById('2504.06227v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06225\">arXiv:2504.06225</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06225\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06225\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Encoder-Decoder Gemma: Improving the Quality-Efficiency Trade-Off via Adaptation\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+B\">Biao Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Moiseev%2C+F\">Fedor Moiseev</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ainslie%2C+J\">Joshua Ainslie</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Suganthan%2C+P\">Paul Suganthan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ma%2C+M\">Min Ma</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Bhupatiraju%2C+S\">Surya Bhupatiraju</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Lebron%2C+F\">Fede Lebron</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Firat%2C+O\">Orhan Firat</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Joulin%2C+A\">Armand Joulin</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Dong%2C+Z\">Zhe Dong</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06225v1-abstract-short\" style=\"display: inline;\">\n",
      "        While decoder-only large language models (<span class=\"search-hit mathjax\">LLMs</span>) have shown impressive results, encoder-decoder models are still widely adopted in real-world applications for their inference efficiency and richer encoder representation. In this paper, we study a novel problem: adapting pretrained decoder-only&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06225v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06225v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06225v1-abstract-full\" style=\"display: none;\">\n",
      "        While decoder-only large language models (<span class=\"search-hit mathjax\">LLMs</span>) have shown impressive results, encoder-decoder models are still widely adopted in real-world applications for their inference efficiency and richer encoder representation. In this paper, we study a novel problem: adapting pretrained decoder-only <span class=\"search-hit mathjax\">LLMs</span> to encoder-decoder, with the goal of leveraging the strengths of both approaches to achieve a more favorable quality-efficiency trade-off. We argue that adaptation not only enables inheriting the capability of decoder-only <span class=\"search-hit mathjax\">LLMs</span> but also reduces the demand for computation compared to pretraining from scratch. We rigorously explore different pretraining objectives and parameter initialization/optimization techniques. Through extensive experiments based on Gemma 2 (2B and 9B) and a suite of newly pretrained mT5-sized models (up to 1.6B), we demonstrate the effectiveness of adaptation and the advantage of encoder-decoder <span class=\"search-hit mathjax\">LLMs</span>. Under similar inference budget, encoder-decoder <span class=\"search-hit mathjax\">LLMs</span> achieve comparable (often better) pretraining performance but substantially better finetuning performance than their decoder-only counterpart. For example, Gemma 2B-2B outperforms Gemma 2B by $\\sim$7\\% after instruction tuning. Encoder-decoder adaptation also allows for flexible combination of different-sized models, where Gemma 9B-2B significantly surpasses Gemma 2B-2B by $&gt;$3\\%. The adapted encoder representation also yields better results on SuperGLUE. We will release our checkpoints to facilitate future research.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06225v1-abstract-full').style.display = 'none'; document.getElementById('2504.06225v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06219\">arXiv:2504.06219</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06219\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06219\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Can Performant <span class=\"search-hit mathjax\">LLMs</span> Be Ethical? Quantifying the Impact of Web Crawling Opt-Outs\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Fan%2C+D\">Dongyang Fan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Sabol%C4%8Dec%2C+V\">Vinko Sabolčec</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ansaripour%2C+M\">Matin Ansaripour</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Tarun%2C+A+K\">Ayush Kumar Tarun</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Jaggi%2C+M\">Martin Jaggi</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Bosselut%2C+A\">Antoine Bosselut</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Schlag%2C+I\">Imanol Schlag</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06219v1-abstract-short\" style=\"display: inline;\">\n",
      "        The increasing adoption of web crawling opt-outs by copyright holders of online content raises critical questions about the impact of data compliance on large language model (<span class=\"search-hit mathjax\">LLM</span>) performance. However, little is known about how these restrictions (and the resultant filtering of pretraining datasets) affect the capabilities of models trained using these corpo&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06219v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06219v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06219v1-abstract-full\" style=\"display: none;\">\n",
      "        The increasing adoption of web crawling opt-outs by copyright holders of online content raises critical questions about the impact of data compliance on large language model (<span class=\"search-hit mathjax\">LLM</span>) performance. However, little is known about how these restrictions (and the resultant filtering of pretraining datasets) affect the capabilities of models trained using these corpora. In this work, we conceptualize this effect as the $\\textit{data compliance gap}$ (DCG), which quantifies the performance difference between models trained on datasets that comply with web crawling opt-outs, and those that do not. We measure the data compliance gap in two settings: pretraining models from scratch and continual pretraining from existing compliant models (simulating a setting where copyrighted data could be integrated later in pretraining). Our experiments with 1.5B models show that, as of January 2025, compliance with web data opt-outs does not degrade general knowledge acquisition (close to 0\\% DCG). However, in specialized domains such as biomedical research, excluding major publishers leads to performance declines. These findings suggest that while general-purpose <span class=\"search-hit mathjax\">LLMs</span> can be trained to perform equally well using fully open data, performance in specialized domains may benefit from access to high-quality copyrighted sources later in training. Our study provides empirical insights into the long-debated trade-off between data compliance and downstream model performance, informing future discussions on AI training practices and policy decisions.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06219v1-abstract-full').style.display = 'none'; document.getElementById('2504.06219v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06214\">arXiv:2504.06214</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06214\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06214\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Xu%2C+C\">Chejian Xu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ping%2C+W\">Wei Ping</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Xu%2C+P\">Peng Xu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+Z\">Zihan Liu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+B\">Boxin Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Shoeybi%2C+M\">Mohammad Shoeybi</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Li%2C+B\">Bo Li</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Catanzaro%2C+B\">Bryan Catanzaro</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06214v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;require models to process and reason over long sequences of text and multimodal data. In this work, we introduce a efficient training recipe for building ultra-long context <span class=\"search-hit mathjax\">LLMs</span> from aligned instruct model, pushing the boundaries of context lengths from 128K to 1M, 2M, and 4M tokens. Our approach leverages efficient continued pretraining strategies to extend&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06214v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06214v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06214v1-abstract-full\" style=\"display: none;\">\n",
      "        Long-context capabilities are essential for a wide range of applications, including document and video understanding, in-context learning, and inference-time scaling, all of which require models to process and reason over long sequences of text and multimodal data. In this work, we introduce a efficient training recipe for building ultra-long context <span class=\"search-hit mathjax\">LLMs</span> from aligned instruct model, pushing the boundaries of context lengths from 128K to 1M, 2M, and 4M tokens. Our approach leverages efficient continued pretraining strategies to extend the context window and employs effective instruction tuning to maintain the instruction-following and reasoning abilities. Our UltraLong-8B, built on Llama3.1-Instruct with our recipe, achieves state-of-the-art performance across a diverse set of long-context benchmarks. Importantly, models trained with our approach maintain competitive performance on standard benchmarks, demonstrating balanced improvements for both long and short context tasks. We further provide an in-depth analysis of key design choices, highlighting the impacts of scaling strategies and data composition. Our findings establish a robust framework for efficiently scaling context lengths while preserving general model capabilities. We release all model weights at: https://ultralong.github.io/.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06214v1-abstract-full').style.display = 'none'; document.getElementById('2504.06214v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06196\">arXiv:2504.06196</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06196\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06196\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        TxGemma: Efficient and Agentic <span class=\"search-hit mathjax\">LLMs</span> for Therapeutics\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+E\">Eric Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Schmidgall%2C+S\">Samuel Schmidgall</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Jaeger%2C+P+F\">Paul F. Jaeger</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+F\">Fan Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Pilgrim%2C+R\">Rory Pilgrim</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Matias%2C+Y\">Yossi Matias</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Barral%2C+J\">Joelle Barral</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Fleet%2C+D\">David Fleet</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Azizi%2C+S\">Shekoofeh Azizi</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06196v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;is a costly and high-risk endeavor that is often plagued by high failure rates. To address this, we introduce TxGemma, a suite of efficient, generalist large language models (<span class=\"search-hit mathjax\">LLMs</span>) capable of therapeutic property prediction as well as interactive reasoning and explainability. Unlike task-specific models, TxGemma synthesizes information from diverse sources,&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06196v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06196v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06196v1-abstract-full\" style=\"display: none;\">\n",
      "        Therapeutic development is a costly and high-risk endeavor that is often plagued by high failure rates. To address this, we introduce TxGemma, a suite of efficient, generalist large language models (<span class=\"search-hit mathjax\">LLMs</span>) capable of therapeutic property prediction as well as interactive reasoning and explainability. Unlike task-specific models, TxGemma synthesizes information from diverse sources, enabling broad application across the therapeutic development pipeline. The suite includes 2B, 9B, and 27B parameter models, fine-tuned from Gemma-2 on a comprehensive dataset of small molecules, proteins, nucleic acids, diseases, and cell lines. Across 66 therapeutic development tasks, TxGemma achieved superior or comparable performance to the state-of-the-art generalist model on 64 (superior on 45), and against state-of-the-art specialist models on 50 (superior on 26). Fine-tuning TxGemma models on therapeutic downstream tasks, such as clinical trial adverse event prediction, requires less training data than fine-tuning base <span class=\"search-hit mathjax\">LLMs</span>, making TxGemma suitable for data-limited applications. Beyond these predictive capabilities, TxGemma features conversational models that bridge the gap between general <span class=\"search-hit mathjax\">LLMs</span> and specialized property predictors. These allow scientists to interact in natural language, provide mechanistic reasoning for predictions based on molecular structure, and engage in scientific discussions. Building on this, we further introduce Agentic-Tx, a generalist therapeutic agentic system powered by Gemini 2.5 that reasons, acts, manages diverse workflows, and acquires external domain knowledge. Agentic-Tx surpasses prior leading models on the Humanity&#39;s Last Exam benchmark (Chemistry &amp; Biology) with 52.3% relative improvement over o3-mini (high) and 26.7% over o3-mini (high) on GPQA (Chemistry) and excels with improvements of 6.3% (ChemBench-Preference) and 2.4% (ChemBench-Mini) over o3-mini (high).\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06196v1-abstract-full').style.display = 'none'; document.getElementById('2504.06196v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06160\">arXiv:2504.06160</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06160\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06160\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computers and Society\">cs.CY</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Social and Information Networks\">cs.SI</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Navigating the Rabbit Hole: Emergent Biases in <span class=\"search-hit mathjax\">LLM</span>-Generated Attack Narratives Targeting Mental Health Groups\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Magu%2C+R\">Rijul Magu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Dutta%2C+A\">Arka Dutta</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Kim%2C+S\">Sean Kim</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=KhudaBukhsh%2C+A+R\">Ashiqur R. KhudaBukhsh</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=De+Choudhury%2C+M\">Munmun De Choudhury</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06160v1-abstract-short\" style=\"display: inline;\">\n",
      "        Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) have been shown to demonstrate imbalanced biases against certain groups. However, the study of unprovoked targeted attacks by&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06160v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06160v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06160v1-abstract-full\" style=\"display: none;\">\n",
      "        Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) have been shown to demonstrate imbalanced biases against certain groups. However, the study of unprovoked targeted attacks by <span class=\"search-hit mathjax\">LLMs</span> towards at-risk populations remains underexplored. Our paper presents three novel contributions: (1) the explicit evaluation of <span class=\"search-hit mathjax\">LLM</span>-generated attacks on highly vulnerable mental health groups; (2) a network-based framework to study the propagation of relative biases; and (3) an assessment of the relative degree of stigmatization that emerges from these attacks. Our analysis of a recently released large-scale bias audit dataset reveals that mental health entities occupy central positions within attack narrative networks, as revealed by a significantly higher mean centrality of closeness (p-value = 4.06e-10) and dense clustering (Gini coefficient = 0.7). Drawing from sociological foundations of stigmatization theory, our stigmatization analysis indicates increased labeling components for mental health disorder-related targets relative to initial targets in generation chains. Taken together, these insights shed light on the structural predilections of large language models to heighten harmful discourse and highlight the need for suitable approaches for mitigation.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06160v1-abstract-full').style.display = 'none'; document.getElementById('2504.06160v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "      <p class=\"comments is-size-7\">\n",
      "        \n",
      "\n",
      "        \n",
      "\n",
      "        \n",
      "          <span class=\"has-text-black-bis has-text-weight-semibold\">ACM Class:</span>\n",
      "          J.4; K.4.1; K.4.2\n",
      "        \n",
      "      </p>\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06143\">arXiv:2504.06143</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06143\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06143\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Software Engineering\">cs.SE</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        ARLO: A Tailorable Approach for Transforming Natural Language Software Requirements into Architecture using <span class=\"search-hit mathjax\">LLMs</span>\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Helmi%2C+T\">Tooraj Helmi</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06143v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;of NL requirements for a system, (2) an existing standard that specifies architecturally relevant software quality attributes, and (3) a readily available Large Language Model (<span class=\"search-hit mathjax\">LLM</span>). Specifically, ARLO determines the subset of NL requirements for a given system that is architecturally relevant and maps that subset to a tailorable matrix of architectural choi&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06143v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06143v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06143v1-abstract-full\" style=\"display: none;\">\n",
      "        Software requirements expressed in natural language (NL) frequently suffer from verbosity, ambiguity, and inconsistency. This creates a range of challenges, including selecting an appropriate architecture for a system and assessing different architectural alternatives. Relying on human expertise to accomplish the task of mapping NL requirements to architecture is time-consuming and error-prone. This paper proposes ARLO, an approach that automates this task by leveraging (1) a set of NL requirements for a system, (2) an existing standard that specifies architecturally relevant software quality attributes, and (3) a readily available Large Language Model (<span class=\"search-hit mathjax\">LLM</span>). Specifically, ARLO determines the subset of NL requirements for a given system that is architecturally relevant and maps that subset to a tailorable matrix of architectural choices. ARLO applies integer linear programming on the architectural-choice matrix to determine the optimal architecture for the current requirements. We demonstrate ARLO&#39;s efficacy using a set of real-world examples. We highlight ARLO&#39;s ability (1) to trace the selected architectural choices to the requirements and (2) to isolate NL requirements that exert a particular influence on a system&#39;s architecture. This allows the identification, comparative assessment, and exploration of alternative architectural choices based on the requirements and constraints expressed therein.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06143v1-abstract-full').style.display = 'none'; document.getElementById('2504.06143v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06136\">arXiv:2504.06136</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06136\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06136\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        QGen Studio: An Adaptive Question-Answer Generation, Training and Evaluation Platform\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Moses%2C+M\">Movina Moses</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Elkaref%2C+M\">Mohab Elkaref</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Barry%2C+J\">James Barry</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Tanaka%2C+S\">Shinnosuke Tanaka</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Kuruvanthodi%2C+V\">Vishnudev Kuruvanthodi</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Herr%2C+N\">Nathan Herr</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Watson%2C+C+D\">Campbell D Watson</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=De+Mel%2C+G\">Geeth De Mel</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06136v1-abstract-short\" style=\"display: inline;\">\n",
      "        We present QGen Studio: an adaptive question-answer generation, training, and evaluation platform. QGen Studio enables users to leverage large language models (<span class=\"search-hit mathjax\">LLMs</span>) to create custom question-answer datasets and fine-tune models on this synthetic data. It features a dataset viewer and model explorer to streamline this process. The dataset viewer provides key&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06136v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06136v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06136v1-abstract-full\" style=\"display: none;\">\n",
      "        We present QGen Studio: an adaptive question-answer generation, training, and evaluation platform. QGen Studio enables users to leverage large language models (<span class=\"search-hit mathjax\">LLMs</span>) to create custom question-answer datasets and fine-tune models on this synthetic data. It features a dataset viewer and model explorer to streamline this process. The dataset viewer provides key metrics and visualizes the context from which the QA pairs are generated, offering insights into data quality. The model explorer supports model comparison, allowing users to contrast the performance of their trained <span class=\"search-hit mathjax\">LLMs</span> against other models, supporting performance benchmarking and refinement. QGen Studio delivers an interactive, end-to-end solution for generating QA datasets and training scalable, domain-adaptable models. The studio will be open-sourced soon, allowing users to deploy it locally.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06136v1-abstract-full').style.display = 'none'; document.getElementById('2504.06136v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06122\">arXiv:2504.06122</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06122\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06122\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Leanabell-Prover: Posttraining Scaling in Formal Reasoning\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+J\">Jingyuan Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+Q\">Qi Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ji%2C+X\">Xingguang Ji</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+Y\">Yahui Liu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Yue%2C+Y\">Yang Yue</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+F\">Fuzheng Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+D\">Di Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhou%2C+G\">Guorui Zhou</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Gai%2C+K\">Kun Gai</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06122v1-abstract-short\" style=\"display: inline;\">\n",
      "        Recent advances in automated theorem proving (ATP) through <span class=\"search-hit mathjax\">LLMs</span> have highlighted the potential of formal reasoning with Lean 4 codes. However, ATP has not yet be revolutionized by the recent posttraining scaling as demonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the entire posttraining of ATP, aiming to align it with breakthroughs&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06122v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06122v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06122v1-abstract-full\" style=\"display: none;\">\n",
      "        Recent advances in automated theorem proving (ATP) through <span class=\"search-hit mathjax\">LLMs</span> have highlighted the potential of formal reasoning with Lean 4 codes. However, ATP has not yet be revolutionized by the recent posttraining scaling as demonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the entire posttraining of ATP, aiming to align it with breakthroughs in reasoning models in natural languages.To begin, we continual train current ATP models with a hybrid dataset, which consists of numerous statement-proof pairs, and additional data aimed at incorporating cognitive behaviors that emulate human reasoning and hypothesis refinement. Next, we explore reinforcement learning with the use of outcome reward returned by Lean 4 compiler. Through our designed continual training and reinforcement learning processes, we have successfully improved existing formal provers, including both DeepSeek-Prover-v1.5 and Goedel-Prover, achieving state-of-the-art performance in the field of whole-proof generation. For example, we achieve a 59.8% pass rate (pass@32) on MiniF2F. This is an on-going project and we will progressively update our findings, release our data and training details.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06122v1-abstract-full').style.display = 'none'; document.getElementById('2504.06122v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">23 pages, 6 figures</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06095\">arXiv:2504.06095</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06095\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06095\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Distributed, Parallel, and Cluster Computing\">cs.DC</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Nonuniform-Tensor-Parallelism: Mitigating GPU failure impact for Scaled-up <span class=\"search-hit mathjax\">LLM</span> Training\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Arfeen%2C+D\">Daiyaan Arfeen</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Mudigere%2C+D\">Dheevatsa Mudigere</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=More%2C+A\">Ankit More</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Gopireddy%2C+B\">Bhargava Gopireddy</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Inci%2C+A\">Ahmet Inci</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ganger%2C+G+R\">Gregory R. Ganger</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06095v1-abstract-short\" style=\"display: inline;\">\n",
      "        <span class=\"search-hit mathjax\">LLM</span> training is scaled up to 10Ks of GPUs by a mix of data-(DP) and model-parallel (MP) execution. Critical to achieving efficiency is tensor-parallel (TP; a form of MP) execution within tightly-coupled subsets of GPUs, referred to as a scale-up domain, and the larger the scale-up domain the better the performance. New datacenter architectures are emerging w&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06095v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06095v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06095v1-abstract-full\" style=\"display: none;\">\n",
      "        <span class=\"search-hit mathjax\">LLM</span> training is scaled up to 10Ks of GPUs by a mix of data-(DP) and model-parallel (MP) execution. Critical to achieving efficiency is tensor-parallel (TP; a form of MP) execution within tightly-coupled subsets of GPUs, referred to as a scale-up domain, and the larger the scale-up domain the better the performance. New datacenter architectures are emerging with more GPUs able to be tightly-coupled in a scale-up domain, such as moving from 8 GPUs to 72 GPUs connected via NVLink. Unfortunately, larger scale-up domains increase the blast-radius of failures, with a failure of single GPU potentially impacting TP execution on the full scale-up domain, which can degrade overall <span class=\"search-hit mathjax\">LLM</span> training throughput dramatically. With as few as 0.1% of GPUs being in a failed state, a high TP-degree job can experience nearly 10% reduction in <span class=\"search-hit mathjax\">LLM</span> training throughput. We propose nonuniform-tensor-parallelism (NTP) to mitigate this amplified impact of GPU failures. In NTP, a DP replica that experiences GPU failures operates at a reduced TP degree, contributing throughput equal to the percentage of still-functional GPUs. We also propose a rack-design with improved electrical and thermal capabilities in order to sustain power-boosting of scale-up domains that have experienced failures; combined with NTP, this can allow the DP replica with the reduced TP degree (i.e., with failed GPUs) to keep up with the others, thereby achieving near-zero throughput loss for large-scale <span class=\"search-hit mathjax\">LLM</span> training.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06095v1-abstract-full').style.display = 'none'; document.getElementById('2504.06095v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06036\">arXiv:2504.06036</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06036\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06036\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Multi-Sense Embeddings for Language Models and Knowledge Distillation\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+Q\">Qitong Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zaki%2C+M+J\">Mohammed J. Zaki</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Kollias%2C+G\">Georgios Kollias</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Kalantzis%2C+V\">Vasileios Kalantzis</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06036v1-abstract-short\" style=\"display: inline;\">\n",
      "        Transformer-based large language models (<span class=\"search-hit mathjax\">LLMs</span>) rely on contextual embeddings which generate different (continuous) representations for the same token depending on its surrounding context. Nonetheless, words and tokens typically have a limited number of senses (or meanings). We propose multi-sense embeddings as a drop-in replacement for each token in order to&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06036v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06036v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06036v1-abstract-full\" style=\"display: none;\">\n",
      "        Transformer-based large language models (<span class=\"search-hit mathjax\">LLMs</span>) rely on contextual embeddings which generate different (continuous) representations for the same token depending on its surrounding context. Nonetheless, words and tokens typically have a limited number of senses (or meanings). We propose multi-sense embeddings as a drop-in replacement for each token in order to capture the range of their uses in a language. To construct a sense embedding dictionary, we apply a clustering algorithm to embeddings generated by an <span class=\"search-hit mathjax\">LLM</span> and consider the cluster centers as representative sense embeddings. In addition, we propose a novel knowledge distillation method that leverages the sense dictionary to learn a smaller student model that mimics the senses from the much larger base <span class=\"search-hit mathjax\">LLM</span> model, offering significant space and inference time savings, while maintaining competitive performance. Via thorough experiments on various benchmarks, we showcase the effectiveness of our sense embeddings and knowledge distillation approach. We share our code at https://github.com/Qitong-Wang/SenseDict\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06036v1-abstract-full').style.display = 'none'; document.getElementById('2504.06036v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">16 pages, 4 figures</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06017\">arXiv:2504.06017</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06017\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06017\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Cryptography and Security\">cs.CR</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        CAI: An Open, Bug Bounty-Ready Cybersecurity AI\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Mayoral-Vilches%2C+V\">Víctor Mayoral-Vilches</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Navarrete-Lozano%2C+L+J\">Luis Javier Navarrete-Lozano</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Sanz-G%C3%B3mez%2C+M\">María Sanz-Gómez</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Espejo%2C+L+S\">Lidia Salas Espejo</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Crespo-%C3%81lvarez%2C+M\">Martiño Crespo-Álvarez</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Oca-Gonzalez%2C+F\">Francisco Oca-Gonzalez</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Balassone%2C+F\">Francesco Balassone</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Glera-Pic%C3%B3n%2C+A\">Alfonso Glera-Picón</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ayucar-Carbajo%2C+U\">Unai Ayucar-Carbajo</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Gil-Uriarte%2C+E\">Endika Gil-Uriarte</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06017v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;750. Based on our results, we argue against <span class=\"search-hit mathjax\">LLM</span>-vendor claims about limited security capabilities. Beyond cybersecurity competitions, CAI demonstrates real-world effectiveness, reaching top-30 in Spain and top-500 worldwide on Hack The Box within a week, while dramatically reducing security testing costs by an average of 156x. Our framework transcends theore&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06017v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06017v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06017v1-abstract-full\" style=\"display: none;\">\n",
      "        By 2028 most cybersecurity actions will be autonomous, with humans teleoperating. We present the first classification of autonomy levels in cybersecurity and introduce Cybersecurity AI (CAI), an open-source framework that democratizes advanced security testing through specialized AI agents. Through rigorous empirical evaluation, we demonstrate that CAI consistently outperforms state-of-the-art results in CTF benchmarks, solving challenges across diverse categories with significantly greater efficiency -up to 3,600x faster than humans in specific tasks and averaging 11x faster overall. CAI achieved first place among AI teams and secured a top-20 position worldwide in the &#34;AI vs Human&#34; CTF live Challenge, earning a monetary reward of $750. Based on our results, we argue against <span class=\"search-hit mathjax\">LLM</span>-vendor claims about limited security capabilities. Beyond cybersecurity competitions, CAI demonstrates real-world effectiveness, reaching top-30 in Spain and top-500 worldwide on Hack The Box within a week, while dramatically reducing security testing costs by an average of 156x. Our framework transcends theoretical benchmarks by enabling non-professionals to discover significant security bugs (CVSS 4.3-7.5) at rates comparable to experts during bug bounty exercises. By combining modular agent design with seamless tool integration and human oversight (HITL), CAI addresses critical market gaps, offering organizations of all sizes access to AI-powered bug bounty security testing previously available only to well-resourced firms -thereby challenging the oligopolistic ecosystem currently dominated by major bug bounty platforms.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06017v1-abstract-full').style.display = 'none'; document.getElementById('2504.06017v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06011\">arXiv:2504.06011</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06011\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06011\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Llama-3-Nanda-10B-Chat: An Open Generative Large Language Model for Hindi\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Choudhury%2C+M\">Monojit Choudhury</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Chauhan%2C+S\">Shivam Chauhan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Das%2C+R+J\">Rocktim Jyoti Das</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Sahnan%2C+D\">Dhruv Sahnan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Han%2C+X\">Xudong Han</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Li%2C+H\">Haonan Li</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Singh%2C+A\">Aaryamonvikram Singh</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Jadhav%2C+A+A\">Alok Anil Jadhav</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Agarwal%2C+U\">Utkarsh Agarwal</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Choudhary%2C+M\">Mukund Choudhary</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Banerjee%2C+D\">Debopriyo Banerjee</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Koto%2C+F\">Fajri Koto</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Bhat%2C+J\">Junaid Bhat</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Shukla%2C+A\">Awantika Shukla</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ghosh%2C+S\">Samujjwal Ghosh</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Kamboj%2C+S\">Samta Kamboj</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Pandit%2C+O\">Onkar Pandit</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Pradhan%2C+L\">Lalit Pradhan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Pal%2C+R\">Rahul Pal</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Sahu%2C+S\">Sunil Sahu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Doraiswamy%2C+S\">Soundar Doraiswamy</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Mullah%2C+P\">Parvez Mullah</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Filali%2C+A+E\">Ali El Filali</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Sengupta%2C+N\">Neha Sengupta</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ramakrishnan%2C+G\">Gokul Ramakrishnan</a>\n",
      "      , et al. (5 additional authors not shown)\n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06011v1-abstract-short\" style=\"display: inline;\">\n",
      "        Developing high-quality large language models (<span class=\"search-hit mathjax\">LLMs</span>) for moderately resourced languages presents unique challenges in data availability, model adaptation, and evaluation. We introduce Llama-3-Nanda-10B-Chat, or Nanda for short, a state-of-the-art Hindi-centric instruction-tuned generative&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06011v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06011v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06011v1-abstract-full\" style=\"display: none;\">\n",
      "        Developing high-quality large language models (<span class=\"search-hit mathjax\">LLMs</span>) for moderately resourced languages presents unique challenges in data availability, model adaptation, and evaluation. We introduce Llama-3-Nanda-10B-Chat, or Nanda for short, a state-of-the-art Hindi-centric instruction-tuned generative <span class=\"search-hit mathjax\">LLM</span>, designed to push the boundaries of open-source Hindi language models. Built upon Llama-3-8B, Nanda incorporates continuous pre-training with expanded transformer blocks, leveraging the Llama Pro methodology. A key challenge was the limited availability of high-quality Hindi text data; we addressed this through rigorous data curation, augmentation, and strategic bilingual training, balancing Hindi and English corpora to optimize cross-linguistic knowledge transfer. With 10 billion parameters, Nanda stands among the top-performing open-source Hindi and multilingual models of similar scale, demonstrating significant advantages over many existing models. We provide an in-depth discussion of training strategies, fine-tuning techniques, safety alignment, and evaluation metrics, demonstrating how these approaches enabled Nanda to achieve state-of-the-art results. By open-sourcing Nanda, we aim to advance research in Hindi <span class=\"search-hit mathjax\">LLMs</span> and support a wide range of real-world applications across academia, industry, and public services.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06011v1-abstract-full').style.display = 'none'; document.getElementById('2504.06011v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.06006\">arXiv:2504.06006</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.06006\">pdf</a>, <a href=\"https://arxiv.org/format/2504.06006\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Neural and Evolutionary Computing\">cs.NE</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Optuna vs Code Llama: Are <span class=\"search-hit mathjax\">LLMs</span> a New Paradigm for Hyperparameter Tuning?\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Kochnev%2C+R\">Roman Kochnev</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Goodarzi%2C+A+T\">Arash Torabi Goodarzi</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Bentyn%2C+Z+A\">Zofia Antonina Bentyn</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ignatov%2C+D\">Dmitry Ignatov</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Timofte%2C+R\">Radu Timofte</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.06006v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;selection is critical for maximizing neural network performance, especially as models grow in complexity. This work investigates the viability of using large language models (<span class=\"search-hit mathjax\">LLMs</span>) for hyperparameter optimization by employing a fine-tuned version of Code Llama. Through parameter-efficient fine-tuning using LoRA, we adapt the&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06006v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06006v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.06006v1-abstract-full\" style=\"display: none;\">\n",
      "        Optimal hyperparameter selection is critical for maximizing neural network performance, especially as models grow in complexity. This work investigates the viability of using large language models (<span class=\"search-hit mathjax\">LLMs</span>) for hyperparameter optimization by employing a fine-tuned version of Code Llama. Through parameter-efficient fine-tuning using LoRA, we adapt the <span class=\"search-hit mathjax\">LLM</span> to generate accurate and efficient hyperparameter recommendations tailored to diverse neural network architectures. Unlike traditional methods such as Optuna, which rely on exhaustive trials, the proposed approach achieves competitive or superior results in terms of Root Mean Square Error (RMSE) while significantly reducing computational overhead. Our approach highlights that <span class=\"search-hit mathjax\">LLM</span>-based optimization not only matches state-of-the-art methods like Tree-structured Parzen Estimators but also accelerates the tuning process. This positions <span class=\"search-hit mathjax\">LLMs</span> as a promising alternative to conventional optimization techniques, particularly for rapid experimentation. Furthermore, the ability to generate hyperparameters in a single inference step makes this method particularly well-suited for resource-constrained environments such as edge devices and mobile applications, where computational efficiency is paramount. The results confirm that <span class=\"search-hit mathjax\">LLMs</span>, beyond their efficiency, offer substantial time savings and comparable stability, underscoring their value in advancing machine learning workflows. All generated hyperparameters are included in the LEMUR Neural Network (NN) Dataset, which is publicly available and serves as an open-source benchmark for hyperparameter optimization research.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.06006v1-abstract-full').style.display = 'none'; document.getElementById('2504.06006v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05995\">arXiv:2504.05995</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05995\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05995\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        NativQA Framework: Enabling <span class=\"search-hit mathjax\">LLMs</span> with Native, Local, and Everyday Knowledge\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Alam%2C+F\">Firoj Alam</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Hasan%2C+M+A\">Md Arid Hasan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Laskar%2C+S+R\">Sahinur Rahman Laskar</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Kutlu%2C+M\">Mucahid Kutlu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Chowdhury%2C+S+A\">Shammur Absar Chowdhury</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05995v1-abstract-short\" style=\"display: inline;\">\n",
      "        The rapid advancement of large language models (<span class=\"search-hit mathjax\">LLMs</span>) has raised concerns about cultural bias, fairness, and their applicability in diverse linguistic and underrepresented regional contexts. To enhance and benchmark the capabilities of&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05995v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05995v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05995v1-abstract-full\" style=\"display: none;\">\n",
      "        The rapid advancement of large language models (<span class=\"search-hit mathjax\">LLMs</span>) has raised concerns about cultural bias, fairness, and their applicability in diverse linguistic and underrepresented regional contexts. To enhance and benchmark the capabilities of <span class=\"search-hit mathjax\">LLMs</span>, there is a need to develop large-scale resources focused on multilingual, local, and cultural contexts. In this study, we propose a framework, NativQA, that can seamlessly construct large-scale, culturally and regionally aligned QA datasets in native languages. The framework utilizes user-defined seed queries and leverages search engines to collect location-specific, everyday information. It has been evaluated across 39 locations in 24 countries and in 7 languages, ranging from extremely low-resource to high-resource languages, which resulted over 300K Question Answer (QA) pairs. The developed resources can be used for <span class=\"search-hit mathjax\">LLM</span> benchmarking and further fine-tuning. The framework has been made publicly available for the community (https://gitlab.com/nativqa/nativqa-framework).\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05995v1-abstract-full').style.display = 'none'; document.getElementById('2504.05995v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">LLMs, Native, Multilingual, Language Diversity, Contextual Understanding, Minority Languages, Culturally Informed, Foundation Models, Large Language Models</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "      <p class=\"comments is-size-7\">\n",
      "        \n",
      "\n",
      "        \n",
      "          <span class=\"has-text-black-bis has-text-weight-semibold\">MSC Class:</span>\n",
      "          68T50\n",
      "        \n",
      "\n",
      "        \n",
      "          <span class=\"has-text-black-bis has-text-weight-semibold\">ACM Class:</span>\n",
      "          F.2.2; I.2.7\n",
      "        \n",
      "      </p>\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05946\">arXiv:2504.05946</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05946\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05946\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Systems and Control\">eess.SY</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        InstructMPC: A Human-<span class=\"search-hit mathjax\">LLM</span>-in-the-Loop Framework for Context-Aware Control\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wu%2C+R\">Ruixiang Wu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ai%2C+J\">Jiahao Ai</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Li%2C+T\">Tongxin Li</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05946v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;which traditional MPC often neglects. We propose \\IMPC, a novel framework that addresses this gap by integrating real-time human instructions through a Large Language Model~(<span class=\"search-hit mathjax\">LLM</span>) to produce context-aware predictions for MPC. Our method employs a Language-to-Distribution~(L2D) module to translate contextual information into predictive disturbance trajectorie&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05946v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05946v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05946v1-abstract-full\" style=\"display: none;\">\n",
      "        Model Predictive Control~(MPC) is a powerful control strategy widely utilized in domains like energy management, building control, and autonomous systems. However, its effectiveness in real-world settings is challenged by the need to incorporate context-specific predictions and expert instructions, which traditional MPC often neglects. We propose \\IMPC, a novel framework that addresses this gap by integrating real-time human instructions through a Large Language Model~(<span class=\"search-hit mathjax\">LLM</span>) to produce context-aware predictions for MPC. Our method employs a Language-to-Distribution~(L2D) module to translate contextual information into predictive disturbance trajectories, which are then incorporated into the MPC optimization. Unlike existing context-aware and language-based MPC models, \\IMPC enables dynamic human-<span class=\"search-hit mathjax\">LLM</span> interaction and fine-tunes the L2D module in a closed loop with theoretical performance guarantees, achieving a regret bound of $O(\\sqrt{T\\log T})$ for linear dynamics when optimized via advanced fine-tuning methods such as Direct Preference Optimization~(DPO) using a tailored loss function.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05946v1-abstract-full').style.display = 'none'; document.getElementById('2504.05946v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05898\">arXiv:2504.05898</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05898\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05898\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Assessing Thai Dialect Performance in <span class=\"search-hit mathjax\">LLMs</span> with Automatic Benchmarks and Human Evaluation\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Limkonchotiwat%2C+P\">Peerat Limkonchotiwat</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Masuk%2C+K\">Kanruethai Masuk</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Nonesung%2C+S\">Surapon Nonesung</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Mai-On%2C+C\">Chalermpun Mai-On</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Nutanong%2C+S\">Sarana Nutanong</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ponwitayarat%2C+W\">Wuttikorn Ponwitayarat</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Manakul%2C+P\">Potsawee Manakul</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05898v1-abstract-short\" style=\"display: inline;\">\n",
      "        Large language models show promising results in various NLP tasks. Despite these successes, the robustness and consistency of <span class=\"search-hit mathjax\">LLMs</span> in underrepresented languages remain largely unexplored, especially concerning local dialects. Existing benchmarks also focus on main dialects, neglecting&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05898v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05898v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05898v1-abstract-full\" style=\"display: none;\">\n",
      "        Large language models show promising results in various NLP tasks. Despite these successes, the robustness and consistency of <span class=\"search-hit mathjax\">LLMs</span> in underrepresented languages remain largely unexplored, especially concerning local dialects. Existing benchmarks also focus on main dialects, neglecting <span class=\"search-hit mathjax\">LLMs</span>&#39; ability on local dialect texts. In this paper, we introduce a Thai local dialect benchmark covering Northern (Lanna), Northeastern (Isan), and Southern (Dambro) Thai, evaluating <span class=\"search-hit mathjax\">LLMs</span> on five NLP tasks: summarization, question answering, translation, conversation, and food-related tasks. Furthermore, we propose a human evaluation guideline and metric for Thai local dialects to assess generation fluency and dialect-specific accuracy. Results show that <span class=\"search-hit mathjax\">LLM</span> performance declines significantly in local Thai dialects compared to standard Thai, with only proprietary models like GPT-4o and Gemini2 demonstrating some fluency\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05898v1-abstract-full').style.display = 'none'; document.getElementById('2504.05898v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">Datasets and codes are available at https://github.com/mrpeerat/Thai_local_benchmark</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05897\">arXiv:2504.05897</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05897\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05897\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Distributed, Parallel, and Cluster Computing\">cs.DC</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        HybriMoE: Hybrid CPU-GPU Scheduling and Cache Management for Efficient MoE Inference\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhong%2C+S\">Shuzhang Zhong</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Sun%2C+Y\">Yanfan Sun</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Liang%2C+L\">Ling Liang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+R\">Runsheng Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Huang%2C+R\">Ru Huang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Li%2C+M\">Meng Li</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05897v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;caching algorithm to mitigate expert activation instability. We implement HybriMoE on top of the kTransformers framework and evaluate it on three widely used MoE-based <span class=\"search-hit mathjax\">LLMs</span>. Experimental results demonstrate that HybriMoE achieves an average speedup of 1.33$\\times$ in the prefill stage and 1.70$\\times$ in the decode stage compared to state-of-the-art hybrid M&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05897v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05897v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05897v1-abstract-full\" style=\"display: none;\">\n",
      "        The Mixture of Experts (MoE) architecture has demonstrated significant advantages as it enables to increase the model capacity without a proportional increase in computation. However, the large MoE model size still introduces substantial memory demands, which usually requires expert offloading on resource-constrained platforms and incurs significant overhead. Hybrid CPU-GPU inference has been proposed to leverage CPU computation to reduce expert loading overhead but faces major challenges: on one hand, the expert activation patterns of MoE models are highly unstable, rendering the fixed mapping strategies in existing works inefficient; on the other hand, the hybrid CPU-GPU schedule for MoE is inherently complex due to the diverse expert sizes, structures, uneven workload distribution, etc. To address these challenges, in this paper, we propose HybriMoE, a hybrid CPU-GPU inference framework that improves resource utilization through a novel CPU-GPU scheduling and cache management system. HybriMoE introduces (i) a dynamic intra-layer scheduling strategy to balance workloads across CPU and GPU, (ii) an impact-driven inter-layer prefetching algorithm, and (iii) a score-based caching algorithm to mitigate expert activation instability. We implement HybriMoE on top of the kTransformers framework and evaluate it on three widely used MoE-based <span class=\"search-hit mathjax\">LLMs</span>. Experimental results demonstrate that HybriMoE achieves an average speedup of 1.33$\\times$ in the prefill stage and 1.70$\\times$ in the decode stage compared to state-of-the-art hybrid MoE inference framework. Our code is available at: https://github.com/PKU-SEC-Lab/HybriMoE.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05897v1-abstract-full').style.display = 'none'; document.getElementById('2504.05897v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">Accepted by DAC 25</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05871\">arXiv:2504.05871</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05871\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05871\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Agent Guide: A Simple Agent Behavioral Watermarking Framework\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Huang%2C+K\">Kaibo Huang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Yang%2C+Z\">Zhongliang Yang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhou%2C+L\">Linna Zhou</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05871v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;platforms, has raised significant concerns about traceability and accountability, particularly in cybersecurity and digital content protection. Traditional large language model (<span class=\"search-hit mathjax\">LLM</span>) watermarking techniques, which rely on token-level manipulations, are ill-suited for agents due to the challenges of behavior tokenization and information loss during behavior-t&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05871v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05871v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05871v1-abstract-full\" style=\"display: none;\">\n",
      "        The increasing deployment of intelligent agents in digital ecosystems, such as social media platforms, has raised significant concerns about traceability and accountability, particularly in cybersecurity and digital content protection. Traditional large language model (<span class=\"search-hit mathjax\">LLM</span>) watermarking techniques, which rely on token-level manipulations, are ill-suited for agents due to the challenges of behavior tokenization and information loss during behavior-to-action translation. To address these issues, we propose Agent Guide, a novel behavioral watermarking framework that embeds watermarks by guiding the agent&#39;s high-level decisions (behavior) through probability biases, while preserving the naturalness of specific executions (action). Our approach decouples agent behavior into two levels, behavior (e.g., choosing to bookmark) and action (e.g., bookmarking with specific tags), and applies watermark-guided biases to the behavior probability distribution. We employ a z-statistic-based statistical analysis to detect the watermark, ensuring reliable extraction over multiple rounds. Experiments in a social media scenario with diverse agent profiles demonstrate that Agent Guide achieves effective watermark detection with a low false positive rate. Our framework provides a practical and robust solution for agent watermarking, with applications in identifying malicious agents and protecting proprietary agent systems.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05871v1-abstract-full').style.display = 'none'; document.getElementById('2504.05871v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "      <p class=\"comments is-size-7\">\n",
      "        \n",
      "\n",
      "        \n",
      "\n",
      "        \n",
      "          <span class=\"has-text-black-bis has-text-weight-semibold\">ACM Class:</span>\n",
      "          K.6.5\n",
      "        \n",
      "      </p>\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05866\">arXiv:2504.05866</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05866\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05866\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Cryptography and Security\">cs.CR</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        CTI-HAL: A Human-Annotated Dataset for Cyber Threat Intelligence Analysis\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Della+Penna%2C+S\">Sofia Della Penna</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Natella%2C+R\">Roberto Natella</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Orbinato%2C+V\">Vittorio Orbinato</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Parracino%2C+L\">Lorenzo Parracino</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Pianese%2C+L\">Luciano Pianese</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05866v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;we conducted an inter-annotator agreement study using Krippendorff alpha, confirming its reliability. Furthermore, the dataset was used to evaluate a Large Language Model (<span class=\"search-hit mathjax\">LLM</span>) in a real-world business context, showing promising generalizability.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05866v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05866v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05866v1-abstract-full\" style=\"display: none;\">\n",
      "        Organizations are increasingly targeted by Advanced Persistent Threats (APTs), which involve complex, multi-stage tactics and diverse techniques. Cyber Threat Intelligence (CTI) sources, such as incident reports and security blogs, provide valuable insights, but are often unstructured and in natural language, making it difficult to automatically extract information. Recent studies have explored the use of AI to perform automatic extraction from CTI data, leveraging existing CTI datasets for performance evaluation and fine-tuning. However, they present challenges and limitations that impact their effectiveness. To overcome these issues, we introduce a novel dataset manually constructed from CTI reports and structured according to the MITRE ATT&amp;CK framework. To assess its quality, we conducted an inter-annotator agreement study using Krippendorff alpha, confirming its reliability. Furthermore, the dataset was used to evaluate a Large Language Model (<span class=\"search-hit mathjax\">LLM</span>) in a real-world business context, showing promising generalizability.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05866v1-abstract-full').style.display = 'none'; document.getElementById('2504.05866v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">Accepted for publication in the Workshop on Attackers and Cybercrime Operations (WACCO 2025), co-located with IEEE European Symposium on Security and Privacy 2025</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05862\">arXiv:2504.05862</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05862\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05862\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Human-Computer Interaction\">cs.HC</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Information Retrieval\">cs.IR</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computational Finance\">q-fin.CP</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Are Generative AI Agents Effective Personalized Financial Advisors?\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Takayanagi%2C+T\">Takehiro Takayanagi</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Izumi%2C+K\">Kiyoshi Izumi</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Sanz-Cruzado%2C+J\">Javier Sanz-Cruzado</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=McCreadie%2C+R\">Richard McCreadie</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ounis%2C+I\">Iadh Ounis</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05862v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;how do these agents perform in complex high-stakes domains, where domain expertise is essential and mistakes carry substantial risk? This paper investigates the effectiveness of <span class=\"search-hit mathjax\">LLM</span>-advisors in the finance domain, focusing on three distinct challenges: (1) eliciting user preferences when users themselves may be unsure of their needs, (2) providing personaliz&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05862v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05862v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05862v1-abstract-full\" style=\"display: none;\">\n",
      "        Large language model-based agents are becoming increasingly popular as a low-cost mechanism to provide personalized, conversational advice, and have demonstrated impressive capabilities in relatively simple scenarios, such as movie recommendations. But how do these agents perform in complex high-stakes domains, where domain expertise is essential and mistakes carry substantial risk? This paper investigates the effectiveness of <span class=\"search-hit mathjax\">LLM</span>-advisors in the finance domain, focusing on three distinct challenges: (1) eliciting user preferences when users themselves may be unsure of their needs, (2) providing personalized guidance for diverse investment preferences, and (3) leveraging advisor personality to build relationships and foster trust. Via a lab-based user study with 64 participants, we show that <span class=\"search-hit mathjax\">LLM</span>-advisors often match human advisor performance when eliciting preferences, although they can struggle to resolve conflicting user needs. When providing personalized advice, the <span class=\"search-hit mathjax\">LLM</span> was able to positively influence user behavior, but demonstrated clear failure modes. Our results show that accurate preference elicitation is key, otherwise, the <span class=\"search-hit mathjax\">LLM</span>-advisor has little impact, or can even direct the investor toward unsuitable assets. More worryingly, users appear insensitive to the quality of advice being given, or worse these can have an inverse relationship. Indeed, users reported a preference for and increased satisfaction as well as emotional trust with <span class=\"search-hit mathjax\">LLMs</span> adopting an extroverted persona, even though those agents provided worse advice.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05862v1-abstract-full').style.display = 'none'; document.getElementById('2504.05862v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05846\">arXiv:2504.05846</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05846\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05846\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Information Retrieval\">cs.IR</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        PathGPT: Leveraging Large Language Models for Personalized Route Generation\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Marcelyn%2C+S+C\">Steeve Cuthbert Marcelyn</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Gao%2C+Y\">Yucen Gao</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+Y\">Yuzhe Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Gao%2C+X\">Xiaofeng Gao</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Chen%2C+G\">Guihai Chen</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05846v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;be necessary to address new possible scenarios,which can be costly as each model must be trained separately. Inspired by recent advances in the field of Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>),we leveraged their natural language understanding capabilities to develop a unified model to solve the PRR problem while being seamlessly adaptable to new scenarios without addit&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05846v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05846v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05846v1-abstract-full\" style=\"display: none;\">\n",
      "        The proliferation of GPS enabled devices has led to the accumulation of a substantial corpus of historical trajectory data. By leveraging these data for training machine learning models,researchers have devised novel data-driven methodologies that address the personalized route recommendation (PRR) problem. In contrast to conventional algorithms such as Dijkstra shortest path algorithm,these novel algorithms possess the capacity to discern and learn patterns within the data,thereby facilitating the generation of more personalized paths. However,once these models have been trained,their application is constrained to the generation of routes that align with their training patterns. This limitation renders them less adaptable to novel scenarios and the deployment of multiple machine learning models might be necessary to address new possible scenarios,which can be costly as each model must be trained separately. Inspired by recent advances in the field of Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>),we leveraged their natural language understanding capabilities to develop a unified model to solve the PRR problem while being seamlessly adaptable to new scenarios without additional training. To accomplish this,we combined the extensive knowledge <span class=\"search-hit mathjax\">LLMs</span> acquired during training with further access to external hand-crafted context information,similar to RAG (Retrieved Augmented Generation) systems,to enhance their ability to generate paths according to user-defined requirements. Extensive experiments on different datasets show a considerable uplift in <span class=\"search-hit mathjax\">LLM</span> performance on the PRR problem.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05846v1-abstract-full').style.display = 'none'; document.getElementById('2504.05846v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05831\">arXiv:2504.05831</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05831\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05831\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Leveraging Robust Optimization for <span class=\"search-hit mathjax\">LLM</span> Alignment under Distribution Shifts\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhu%2C+M\">Mingye Zhu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+Y\">Yi Liu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Guo%2C+J\">Junbo Guo</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+Q\">Quan Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+Y\">Yongdong Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Mao%2C+Z\">Zhendong Mao</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05831v1-abstract-short\" style=\"display: inline;\">\n",
      "        Large language models (<span class=\"search-hit mathjax\">LLMs</span>) increasingly rely on preference alignment methods to steer outputs toward human values, yet these methods are often constrained by the scarcity of high-quality human-annotated data. To tackle this, recent approaches have turned to synthetic data generated by <span class=\"search-hit mathjax\">LLMs</span> as a scalable alternative.&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05831v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05831v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05831v1-abstract-full\" style=\"display: none;\">\n",
      "        Large language models (<span class=\"search-hit mathjax\">LLMs</span>) increasingly rely on preference alignment methods to steer outputs toward human values, yet these methods are often constrained by the scarcity of high-quality human-annotated data. To tackle this, recent approaches have turned to synthetic data generated by <span class=\"search-hit mathjax\">LLMs</span> as a scalable alternative. However, synthetic data can introduce distribution shifts, compromising the nuanced human preferences that are essential for desirable outputs. In this paper, we propose a novel distribution-aware optimization framework that improves preference alignment in the presence of such shifts. Our approach first estimates the likelihood ratios between the target and training distributions leveraging a learned classifier, then it minimizes the worst-case loss over data regions that reflect the target human-preferred distribution. By explicitly prioritizing the target distribution during optimization, our method mitigates the adverse effects of distributional variation and enhances the generation of responses that faithfully reflect human values.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05831v1-abstract-full').style.display = 'none'; document.getElementById('2504.05831v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05812\">arXiv:2504.05812</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05812\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05812\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Right Question is Already Half the Answer: Fully Unsupervised <span class=\"search-hit mathjax\">LLM</span> Reasoning Incentivization\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+Q\">Qingyang Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wu%2C+H\">Haitao Wu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+C\">Changqing Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhao%2C+P\">Peilin Zhao</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Bian%2C+Y\">Yatao Bian</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05812v1-abstract-short\" style=\"display: inline;\">\n",
      "        While large language models (<span class=\"search-hit mathjax\">LLMs</span>) have demonstrated exceptional capabilities in challenging tasks such as mathematical reasoning, existing methods to enhance reasoning ability predominantly rely on supervised fine-tuning (SFT) followed by reinforcement learning (RL) on reasoning-specific data after pre-training. However, these approaches critically depend o&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05812v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05812v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05812v1-abstract-full\" style=\"display: none;\">\n",
      "        While large language models (<span class=\"search-hit mathjax\">LLMs</span>) have demonstrated exceptional capabilities in challenging tasks such as mathematical reasoning, existing methods to enhance reasoning ability predominantly rely on supervised fine-tuning (SFT) followed by reinforcement learning (RL) on reasoning-specific data after pre-training. However, these approaches critically depend on external supervisions--such as human labelled reasoning traces, verified golden answers, or pre-trained reward models--which limits scalability and practical applicability. In this work, we propose Entropy Minimized Policy Optimization (EMPO), which makes an early attempt at fully unsupervised <span class=\"search-hit mathjax\">LLM</span> reasoning incentivization. EMPO does not require any supervised information for incentivizing reasoning capabilities (i.e., neither verifiable reasoning traces, problems with golden answers, nor additional pre-trained reward models). By continuously minimizing the predictive entropy of <span class=\"search-hit mathjax\">LLMs</span> on unlabeled user queries in a latent semantic space, EMPO enables purely self-supervised evolution of reasoning capabilities with strong flexibility and practicality. Our experiments demonstrate competitive performance of EMPO on both mathematical reasoning and free-form commonsense reasoning tasks. Specifically, without any supervised signals, EMPO boosts the accuracy of Qwen2.5-Math-7B Base from 30.7\\% to 48.1\\% on mathematical benchmarks and improves truthfulness accuracy of Qwen2.5-7B Instruct from 87.16\\% to 97.25\\% on TruthfulQA.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05812v1-abstract-full').style.display = 'none'; document.getElementById('2504.05812v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">Ongoing work</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05804\">arXiv:2504.05804</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05804\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05804\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Information Retrieval\">cs.IR</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        StealthRank: <span class=\"search-hit mathjax\">LLM</span> Ranking Manipulation via Stealthy Prompt Optimization\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Tang%2C+Y\">Yiming Tang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Fan%2C+Y\">Yi Fan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Yu%2C+C\">Chenxiao Yu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Yang%2C+T\">Tiankai Yang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhao%2C+Y\">Yue Zhao</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Hu%2C+X\">Xiyang Hu</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05804v1-abstract-short\" style=\"display: inline;\">\n",
      "        The integration of large language models (<span class=\"search-hit mathjax\">LLMs</span>) into information retrieval systems introduces new attack surfaces, particularly for adversarial ranking manipulations. We present StealthRank, a novel adversarial ranking attack that manipulates&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05804v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05804v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05804v1-abstract-full\" style=\"display: none;\">\n",
      "        The integration of large language models (<span class=\"search-hit mathjax\">LLMs</span>) into information retrieval systems introduces new attack surfaces, particularly for adversarial ranking manipulations. We present StealthRank, a novel adversarial ranking attack that manipulates <span class=\"search-hit mathjax\">LLM</span>-driven product recommendation systems while maintaining textual fluency and stealth. Unlike existing methods that often introduce detectable anomalies, StealthRank employs an energy-based optimization framework combined with Langevin dynamics to generate StealthRank Prompts (SRPs)-adversarial text sequences embedded within product descriptions that subtly yet effectively influence <span class=\"search-hit mathjax\">LLM</span> ranking mechanisms. We evaluate StealthRank across multiple <span class=\"search-hit mathjax\">LLMs</span>, demonstrating its ability to covertly boost the ranking of target products while avoiding explicit manipulation traces that can be easily detected. Our results show that StealthRank consistently outperforms state-of-the-art adversarial ranking baselines in both effectiveness and stealth, highlighting critical vulnerabilities in <span class=\"search-hit mathjax\">LLM</span>-driven recommendation systems.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05804v1-abstract-full').style.display = 'none'; document.getElementById('2504.05804v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05801\">arXiv:2504.05801</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05801\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05801\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        From Superficial to Deep: Integrating External Knowledge for Follow-up Question Generation Using Knowledge Graph and <span class=\"search-hit mathjax\">LLM</span>\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+J\">Jianyu Liu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Huang%2C+Y\">Yi Huang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Bi%2C+S\">Sheng Bi</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Feng%2C+J\">Junlan Feng</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Qi%2C+G\">Guilin Qi</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05801v1-abstract-short\" style=\"display: inline;\">\n",
      "        In a conversational system, dynamically generating follow-up questions based on context can help users explore information and provide a better user experience. Humans are usually able to ask questions that involve some general life knowledge and demonstrate higher order cognitive skills. However, the questions generated by existing methods are often limited to shallow contextual questions that ar&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05801v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05801v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05801v1-abstract-full\" style=\"display: none;\">\n",
      "        In a conversational system, dynamically generating follow-up questions based on context can help users explore information and provide a better user experience. Humans are usually able to ask questions that involve some general life knowledge and demonstrate higher order cognitive skills. However, the questions generated by existing methods are often limited to shallow contextual questions that are uninspiring and have a large gap to the human level. In this paper, we propose a three-stage external knowledge-enhanced follow-up question generation method, which generates questions by identifying contextual topics, constructing a knowledge graph (KG) online, and finally combining these with a large language model to generate the final question. The model generates information-rich and exploratory follow-up questions by introducing external common sense knowledge and performing a knowledge fusion operation. Experiments show that compared to baseline models, our method generates questions that are more informative and closer to human questioning levels while maintaining contextual relevance.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05801v1-abstract-full').style.display = 'none'; document.getElementById('2504.05801v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">Proceedings of the 31st International Conference on Computational Linguistics</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05786\">arXiv:2504.05786</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05786\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05786\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        How to Enable <span class=\"search-hit mathjax\">LLM</span> with 3D Capacity? A Survey of Spatial Reasoning in <span class=\"search-hit mathjax\">LLM</span>\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zha%2C+J\">Jirong Zha</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Fan%2C+Y\">Yuxuan Fan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Yang%2C+X\">Xiao Yang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Gao%2C+C\">Chen Gao</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Chen%2C+X\">Xinlei Chen</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05786v1-abstract-short\" style=\"display: inline;\">\n",
      "        3D spatial understanding is essential in real-world applications such as robotics, autonomous vehicles, virtual reality, and medical imaging. Recently, Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>), having demonstrated remarkable success across various domains, have been leveraged to enhance 3D understanding tasks, showing potential to surpass traditional computer vision met&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05786v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05786v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05786v1-abstract-full\" style=\"display: none;\">\n",
      "        3D spatial understanding is essential in real-world applications such as robotics, autonomous vehicles, virtual reality, and medical imaging. Recently, Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>), having demonstrated remarkable success across various domains, have been leveraged to enhance 3D understanding tasks, showing potential to surpass traditional computer vision methods. In this survey, we present a comprehensive review of methods integrating <span class=\"search-hit mathjax\">LLMs</span> with 3D spatial understanding. We propose a taxonomy that categorizes existing methods into three branches: image-based methods deriving 3D understanding from 2D visual data, point cloud-based methods working directly with 3D representations, and hybrid modality-based methods combining multiple data streams. We systematically review representative methods along these categories, covering data representations, architectural modifications, and training strategies that bridge textual and 3D modalities. Finally, we discuss current limitations, including dataset scarcity and computational challenges, while highlighting promising research directions in spatial perception, multi-modal fusion, and real-world applications.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05786v1-abstract-full').style.display = 'none'; document.getElementById('2504.05786v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">9 pages, 5 figures</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05764\">arXiv:2504.05764</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05764\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05764\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Layer-Aware Embedding Fusion for <span class=\"search-hit mathjax\">LLMs</span> in Text Classifications\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Gwak%2C+J\">Jiho Gwak</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Jung%2C+Y\">Yuchul Jung</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05764v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;for enhancing performance across various NLP tasks. However, systematic guidelines for selecting optimal layers and developing effective fusion strategies for the integration of <span class=\"search-hit mathjax\">LLMs</span> remain underexplored. In this study, we propose a layer-aware embedding selection method and investigate how to quantitatively evaluate different layers to identify the most imp&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05764v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05764v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05764v1-abstract-full\" style=\"display: none;\">\n",
      "        Embedding fusion has emerged as an effective approach for enhancing performance across various NLP tasks. However, systematic guidelines for selecting optimal layers and developing effective fusion strategies for the integration of <span class=\"search-hit mathjax\">LLMs</span> remain underexplored. In this study, we propose a layer-aware embedding selection method and investigate how to quantitatively evaluate different layers to identify the most important ones for downstream NLP tasks, showing that the critical layers vary depending on the dataset. We also explore how combining embeddings from multiple <span class=\"search-hit mathjax\">LLMs</span>, without requiring model fine-tuning, can improve performance. Experiments on four English text classification datasets (SST-2, MR, R8, and R52) demonstrate that different layers in <span class=\"search-hit mathjax\">LLMs</span> exhibit varying degrees of representational strength for classification, and that combining embeddings from different models can enhance performance if the models exhibit complementary characteristics. Additionally, we discuss resources overhead (memory and inference time) to provide a balanced perspective on the real world feasibility of embedding fusion. Future work will explore multilingual and domain specific datasets, as well as techniques for automating layer selection, to improve both performance and scalability.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05764v1-abstract-full').style.display = 'none'; document.getElementById('2504.05764v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">11 pages, 3 figures, Preprint</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "      <p class=\"comments is-size-7\">\n",
      "        \n",
      "\n",
      "        \n",
      "\n",
      "        \n",
      "          <span class=\"has-text-black-bis has-text-weight-semibold\">ACM Class:</span>\n",
      "          I.2.7; I.2.6\n",
      "        \n",
      "      </p>\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05747\">arXiv:2504.05747</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05747\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05747\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        SEA-LION: Southeast Asian Languages in One Network\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ng%2C+R\">Raymond Ng</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Nguyen%2C+T+N\">Thanh Ngan Nguyen</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Huang%2C+Y\">Yuli Huang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Tai%2C+N+C\">Ngee Chia Tai</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Leong%2C+W+Y\">Wai Yi Leong</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Leong%2C+W+Q\">Wei Qi Leong</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Yong%2C+X\">Xianbin Yong</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ngui%2C+J+G\">Jian Gang Ngui</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Susanto%2C+Y\">Yosephine Susanto</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Cheng%2C+N\">Nicholas Cheng</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Rengarajan%2C+H\">Hamsawardhini Rengarajan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Limkonchotiwat%2C+P\">Peerat Limkonchotiwat</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Hulagadri%2C+A+V\">Adithya Venkatadri Hulagadri</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Teng%2C+K+W\">Kok Wai Teng</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Tong%2C+Y+Y\">Yeo Yeow Tong</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Siow%2C+B\">Bryan Siow</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Teo%2C+W+Y\">Wei Yi Teo</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Lau%2C+W\">Wayne Lau</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Tan%2C+C+M\">Choon Meng Tan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ong%2C+B\">Brandon Ong</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ong%2C+Z+H\">Zhi Hao Ong</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Montalan%2C+J+R\">Jann Railey Montalan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Chan%2C+A\">Adwin Chan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Antonyrex%2C+S\">Sajeban Antonyrex</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Lee%2C+R\">Ren Lee</a>\n",
      "      , et al. (6 additional authors not shown)\n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05747v1-abstract-short\" style=\"display: inline;\">\n",
      "        Recently, Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) have dominated much of the artificial intelligence scene with their ability to process and generate natural languages. However, the majority of&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05747v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05747v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05747v1-abstract-full\" style=\"display: none;\">\n",
      "        Recently, Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) have dominated much of the artificial intelligence scene with their ability to process and generate natural languages. However, the majority of <span class=\"search-hit mathjax\">LLM</span> research and development remains English-centric, leaving low-resource languages such as those in the Southeast Asian (SEA) region under-represented. To address this representation gap, we introduce Llama-SEA-LION-v3-8B-IT and Gemma-SEA-LION-v3-9B-IT, two cutting-edge multilingual <span class=\"search-hit mathjax\">LLMs</span> designed for SEA languages. The SEA-LION family of <span class=\"search-hit mathjax\">LLMs</span> supports 11 SEA languages, namely English, Chinese, Indonesian, Vietnamese, Malay, Thai, Burmese, Lao, Filipino, Tamil, and Khmer. Our work leverages large-scale multilingual continued pre-training with a comprehensive post-training regime involving multiple stages of instruction fine-tuning, alignment, and model merging. Evaluation results on multilingual benchmarks indicate that our models achieve state-of-the-art performance across <span class=\"search-hit mathjax\">LLMs</span> supporting SEA languages. We open-source the models to benefit the wider SEA community.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05747v1-abstract-full').style.display = 'none'; document.getElementById('2504.05747v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">We released our model at https://huggingface.co/collections/aisingapore/sea-lionv3-672589a39cdadd6a5b199581</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05738\">arXiv:2504.05738</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05738\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05738\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Software Engineering\">cs.SE</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        <span class=\"search-hit mathjax\">LLM</span>-assisted Mutation for Whitebox API Testing\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Li%2C+J\">Jia Li</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Shen%2C+J\">Jiacheng Shen</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Su%2C+Y\">Yuxin Su</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Lyu%2C+M+R\">Michael R. Lyu</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05738v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;coverage metrics. To address this issue, we propose MioHint, a novel white-box API testing approach that leverages the code comprehension capabilities of Large Language Model (<span class=\"search-hit mathjax\">LLM</span>) to boost API testing. The key challenge of&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05738v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05738v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05738v1-abstract-full\" style=\"display: none;\">\n",
      "        Cloud applications heavily rely on APIs to communicate with each other and exchange data. To ensure the reliability of cloud applications, cloud providers widely adopt API testing techniques. Unfortunately, existing API testing approaches are insufficient to reach strict conditions, a problem known as fitness plateaus, due to the lack of gradient provided by coverage metrics. To address this issue, we propose MioHint, a novel white-box API testing approach that leverages the code comprehension capabilities of Large Language Model (<span class=\"search-hit mathjax\">LLM</span>) to boost API testing. The key challenge of <span class=\"search-hit mathjax\">LLM</span>-based API testing lies in system-level testing, which emphasizes the dependencies between requests and targets across functions and files, thereby making the entire codebase the object of analysis. However, feeding the entire codebase to an <span class=\"search-hit mathjax\">LLM</span> is impractical due to its limited context length and short memory. MioHint addresses this challenge by synergizing static analysis with <span class=\"search-hit mathjax\">LLMs</span>. We retrieve relevant code with data-dependency analysis at the statement level, including def-use analysis for variables used in the target and function expansion for subfunctions called by the target.\n",
      "  To evaluate the effectiveness of our method, we conducted experiments across 16 real-world REST API services. The findings reveal that MioHint achieves an average increase of 4.95% absolute in line coverage compared to the baseline, EvoMaster, alongside a remarkable factor of 67x improvement in mutation accuracy. Furthermore, our method successfully covers over 57% of hard-to-cover targets while in baseline the coverage is less than 10%.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05738v1-abstract-full').style.display = 'none'; document.getElementById('2504.05738v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05736\">arXiv:2504.05736</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05736\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05736\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Rank-Then-Score: Enhancing Large Language Models for Automated Essay Scoring\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Cai%2C+Y\">Yida Cai</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Liang%2C+K\">Kun Liang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Lee%2C+S\">Sanwoo Lee</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+Q\">Qinghan Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wu%2C+Y\">Yunfang Wu</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05736v1-abstract-short\" style=\"display: inline;\">\n",
      "        In recent years, large language models (<span class=\"search-hit mathjax\">LLMs</span>) achieve remarkable success across a variety of tasks. However, their potential in the domain of Automated Essay Scoring (AES) remains largely underexplored. Moreover, compared to English data, the methods for Chinese AES is not well developed. In this paper, we propose Rank-Then-Score (RTS), a fine-tuning framewo&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05736v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05736v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05736v1-abstract-full\" style=\"display: none;\">\n",
      "        In recent years, large language models (<span class=\"search-hit mathjax\">LLMs</span>) achieve remarkable success across a variety of tasks. However, their potential in the domain of Automated Essay Scoring (AES) remains largely underexplored. Moreover, compared to English data, the methods for Chinese AES is not well developed. In this paper, we propose Rank-Then-Score (RTS), a fine-tuning framework based on large language models to enhance their essay scoring capabilities. Specifically, we fine-tune the ranking model (Ranker) with feature-enriched data, and then feed the output of the ranking model, in the form of a candidate score set, with the essay content into the scoring model (Scorer) to produce the final score. Experimental results on two benchmark datasets, HSK and ASAP, demonstrate that RTS consistently outperforms the direct prompting (Vanilla) method in terms of average QWK across all <span class=\"search-hit mathjax\">LLMs</span> and datasets, and achieves the best performance on Chinese essay scoring using the HSK dataset.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05736v1-abstract-full').style.display = 'none'; document.getElementById('2504.05736v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">17 pages</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05732\">arXiv:2504.05732</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05732\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05732\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        <span class=\"search-hit mathjax\">LLM</span>$\\times$MapReduce-V2: Entropy-Driven Convolutional Test-Time Scaling for Generating Long-Form Articles from Extremely Long Resources\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+H\">Haoyu Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Fu%2C+Y\">Yujia Fu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+Z\">Zhu Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+S\">Shuo Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ren%2C+Z\">Zirui Ren</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+X\">Xiaorong Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Li%2C+Z\">Zhili Li</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=He%2C+C\">Chaoqun He</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=An%2C+B\">Bo An</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+Z\">Zhiyuan Liu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Sun%2C+M\">Maosong Sun</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05732v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;in long-to-long generation lies in effectively integrating and analyzing relevant information from extensive inputs, which remains difficult for current large language models (<span class=\"search-hit mathjax\">LLMs</span>). In this paper, we propose <span class=\"search-hit mathjax\">LLM</span>$\\times$MapReduce-V2, a novel test-time scaling strategy designed to enhance the ability of&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05732v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05732v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05732v1-abstract-full\" style=\"display: none;\">\n",
      "        Long-form generation is crucial for a wide range of practical applications, typically categorized into short-to-long and long-to-long generation. While short-to-long generations have received considerable attention, generating long texts from extremely long resources remains relatively underexplored. The primary challenge in long-to-long generation lies in effectively integrating and analyzing relevant information from extensive inputs, which remains difficult for current large language models (<span class=\"search-hit mathjax\">LLMs</span>). In this paper, we propose <span class=\"search-hit mathjax\">LLM</span>$\\times$MapReduce-V2, a novel test-time scaling strategy designed to enhance the ability of <span class=\"search-hit mathjax\">LLMs</span> to process extremely long inputs. Drawing inspiration from convolutional neural networks, which iteratively integrate local features into higher-level global representations, <span class=\"search-hit mathjax\">LLM</span>$\\times$MapReduce-V2 utilizes stacked convolutional scaling layers to progressively expand the understanding of input materials. Both quantitative and qualitative experimental results demonstrate that our approach substantially enhances the ability of <span class=\"search-hit mathjax\">LLMs</span> to process long inputs and generate coherent, informative long-form articles, outperforming several representative baselines.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05732v1-abstract-full').style.display = 'none'; document.getElementById('2504.05732v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05731\">arXiv:2504.05731</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05731\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05731\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Information Retrieval\">cs.IR</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Retrieval Augmented Generation with Collaborative Filtering for Personalized Text Generation\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Shi%2C+T\">Teng Shi</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Xu%2C+J\">Jun Xu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+X\">Xiao Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zang%2C+X\">Xiaoxue Zang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zheng%2C+K\">Kai Zheng</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Song%2C+Y\">Yang Song</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Li%2C+H\">Han Li</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05731v1-abstract-short\" style=\"display: inline;\">\n",
      "        Recently, the personalization of Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) to generate content that aligns with individual user preferences has garnered widespread attention. Personalized Retrieval-Augmented Generation (RAG), which retrieves relevant documents from the user&#39;s history to reflect their preferences and enhance&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05731v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05731v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05731v1-abstract-full\" style=\"display: none;\">\n",
      "        Recently, the personalization of Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) to generate content that aligns with individual user preferences has garnered widespread attention. Personalized Retrieval-Augmented Generation (RAG), which retrieves relevant documents from the user&#39;s history to reflect their preferences and enhance <span class=\"search-hit mathjax\">LLM</span> generation, is one commonly used approach for personalization. However, existing personalized RAG methods do not consider that the histories of similar users can also assist in personalized generation for the current user, meaning that collaborative information between users can also benefit personalized generation. Inspired by the application of collaborative filtering in recommender systems, we propose a method called CFRAG, which adapts Collaborative Filtering to RAG for personalized text generation. However, this presents two challenges: (1)~how to incorporate collaborative information without explicit user similarity labels? (2)~how to retrieve documents that support personalized <span class=\"search-hit mathjax\">LLM</span> generation? For Challenge 1, we use contrastive learning to train user embeddings to retrieve similar users and introduce collaborative information. For Challenge 2, we design a personalized retriever and reranker to retrieve the top-$k$ documents from these users&#39; histories. We take into account the user&#39;s preference during retrieval and reranking. Then we leverage feedback from the <span class=\"search-hit mathjax\">LLM</span> to fine-tune the personalized retriever and reranker, enabling them to retrieve documents that meet the personalized generation needs of the <span class=\"search-hit mathjax\">LLM</span>. Experimental results on the Language Model Personalization (LaMP) benchmark validate the effectiveness of CFRAG. Further analysis confirms the importance of incorporating collaborative information.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05731v1-abstract-full').style.display = 'none'; document.getElementById('2504.05731v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">Accepted by SIGIR 2025</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05730\">arXiv:2504.05730</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05730\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05730\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Information Retrieval\">cs.IR</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Unified Generative Search and Recommendation\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Shi%2C+T\">Teng Shi</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Xu%2C+J\">Jun Xu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+X\">Xiao Zhang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zang%2C+X\">Xiaoxue Zang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zheng%2C+K\">Kai Zheng</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Song%2C+Y\">Yang Song</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Yu%2C+E\">Enyun Yu</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05730v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;and (2) guiding the model to distinguish and adapt to the unique demands of search and recommendation. The emergence of generative retrieval with Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) presents new possibilities. This paradigm encodes items as identifiers and frames both search and recommendation as sequential generation tasks, offering the flexibility to leverage mu&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05730v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05730v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05730v1-abstract-full\" style=\"display: none;\">\n",
      "        Modern commercial platforms typically offer both search and recommendation functionalities to serve diverse user needs, making joint modeling of these tasks an appealing direction. While prior work has shown that integrating search and recommendation can be mutually beneficial, it also reveals a performance trade-off: enhancements in one task often come at the expense of the other. This challenge arises from their distinct information requirements: search emphasizes semantic relevance between queries and items, whereas recommendation depends more on collaborative signals among users and items. Effectively addressing this trade-off requires tackling two key problems: (1) integrating both semantic and collaborative signals into item representations, and (2) guiding the model to distinguish and adapt to the unique demands of search and recommendation. The emergence of generative retrieval with Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) presents new possibilities. This paradigm encodes items as identifiers and frames both search and recommendation as sequential generation tasks, offering the flexibility to leverage multiple identifiers and task-specific prompts. In light of this, we introduce GenSAR, a unified generative framework for balanced search and recommendation. Our approach designs dual-purpose identifiers and tailored training strategies to incorporate complementary signals and align with task-specific objectives. Experiments on both public and commercial datasets demonstrate that GenSAR effectively reduces the trade-off and achieves state-of-the-art performance on both tasks.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05730v1-abstract-full').style.display = 'none'; document.getElementById('2504.05730v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05716\">arXiv:2504.05716</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05716\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05716\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computers and Society\">cs.CY</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Single-Agent vs. Multi-Agent <span class=\"search-hit mathjax\">LLM</span> Strategies for Automated Student Reflection Assessment\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Li%2C+G\">Gen Li</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Chen%2C+L\">Li Chen</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Tang%2C+C\">Cheng Tang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=%C5%A0v%C3%A1bensk%C3%BD%2C+V\">Valdemar Švábenský</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Deguchi%2C+D\">Daisuke Deguchi</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Yamashita%2C+T\">Takayoshi Yamashita</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Shimada%2C+A\">Atsushi Shimada</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05716v1-abstract-short\" style=\"display: inline;\">\n",
      "        We explore the use of Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) for automated assessment of open-text student reflections and prediction of academic performance. Traditional methods for evaluating reflections are time-consuming and may not scale effectively in educational settings. In this work, we employ&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05716v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05716v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05716v1-abstract-full\" style=\"display: none;\">\n",
      "        We explore the use of Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) for automated assessment of open-text student reflections and prediction of academic performance. Traditional methods for evaluating reflections are time-consuming and may not scale effectively in educational settings. In this work, we employ <span class=\"search-hit mathjax\">LLMs</span> to transform student reflections into quantitative scores using two assessment strategies (single-agent and multi-agent) and two prompting techniques (zero-shot and few-shot). Our experiments, conducted on a dataset of 5,278 reflections from 377 students over three academic terms, demonstrate that the single-agent with few-shot strategy achieves the highest match rate with human evaluations. Furthermore, models utilizing <span class=\"search-hit mathjax\">LLM</span>-assessed reflection scores outperform baselines in both at-risk student identification and grade prediction tasks. These findings suggest that <span class=\"search-hit mathjax\">LLMs</span> can effectively automate reflection assessment, reduce educators&#39; workload, and enable timely support for students who may need additional assistance. Our work emphasizes the potential of integrating advanced generative AI technologies into educational practices to enhance student engagement and academic success.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05716v1-abstract-full').style.display = 'none'; document.getElementById('2504.05716v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">To be published in Proceedings of the 29th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2025)</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "      <p class=\"comments is-size-7\">\n",
      "        \n",
      "\n",
      "        \n",
      "\n",
      "        \n",
      "          <span class=\"has-text-black-bis has-text-weight-semibold\">ACM Class:</span>\n",
      "          I.2; I.6; K.3\n",
      "        \n",
      "      </p>\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05711\">arXiv:2504.05711</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05711\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05711\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Digital Libraries\">cs.DL</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Information Retrieval\">cs.IR</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Automated Archival Descriptions with Federated Intelligence of <span class=\"search-hit mathjax\">LLMs</span>\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Groppe%2C+J\">Jinghua Groppe</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Marquet%2C+A\">Andreas Marquet</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Walz%2C+A\">Annabel Walz</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Groppe%2C+S\">Sven Groppe</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05711v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;creating metadata descriptions for archival materials is a tedious and error-prone task. This work aims at exploring the potential of agentic AI and large language models (<span class=\"search-hit mathjax\">LLMs</span>) in addressing the challenges of implementing a standardized archival description process. To this end, we introduce an agentic AI-driven system for automated generation of high-quali&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05711v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05711v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05711v1-abstract-full\" style=\"display: none;\">\n",
      "        Enforcing archival standards requires specialized expertise, and manually creating metadata descriptions for archival materials is a tedious and error-prone task. This work aims at exploring the potential of agentic AI and large language models (<span class=\"search-hit mathjax\">LLMs</span>) in addressing the challenges of implementing a standardized archival description process. To this end, we introduce an agentic AI-driven system for automated generation of high-quality metadata descriptions of archival materials. We develop a federated optimization approach that unites the intelligence of multiple <span class=\"search-hit mathjax\">LLMs</span> to construct optimal archival metadata. We also suggest methods to overcome the challenges associated with using <span class=\"search-hit mathjax\">LLMs</span> for consistent metadata generation. To evaluate the feasibility and effectiveness of our techniques, we conducted extensive experiments using a real-world dataset of archival materials, which covers a variety of document types and data formats. The evaluation results demonstrate the feasibility of our techniques and highlight the superior performance of the federated optimization approach compared to single-model solutions in metadata quality and reliability.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05711v1-abstract-full').style.display = 'none'; document.getElementById('2504.05711v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">15 pages</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "      <p class=\"comments is-size-7\">\n",
      "        \n",
      "\n",
      "        \n",
      "\n",
      "        \n",
      "          <span class=\"has-text-black-bis has-text-weight-semibold\">ACM Class:</span>\n",
      "          I.2\n",
      "        \n",
      "      </p>\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05694\">arXiv:2504.05694</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05694\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05694\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Information Retrieval\">cs.IR</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Large Language Models Enhanced Hyperbolic Space Recommender Systems\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Cheng%2C+W\">Wentao Cheng</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Qin%2C+Z\">Zhida Qin</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wu%2C+Z\">Zexue Wu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhou%2C+P\">Pengzhan Zhou</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Huang%2C+T\">Tianyu Huang</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05694v1-abstract-short\" style=\"display: inline;\">\n",
      "        Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) have attracted significant attention in recommender systems for their excellent world knowledge capabilities. However, existing methods that rely on Euclidean space struggle to capture the rich hierarchical information inherent in textual and semantic data, which is essential for capturing user preferences. The geometric properti&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05694v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05694v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05694v1-abstract-full\" style=\"display: none;\">\n",
      "        Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) have attracted significant attention in recommender systems for their excellent world knowledge capabilities. However, existing methods that rely on Euclidean space struggle to capture the rich hierarchical information inherent in textual and semantic data, which is essential for capturing user preferences. The geometric properties of hyperbolic space offer a promising solution to address this issue. Nevertheless, integrating <span class=\"search-hit mathjax\">LLMs</span>-based methods with hyperbolic space to effectively extract and incorporate diverse hierarchical information is non-trivial. To this end, we propose a model-agnostic framework, named HyperLLM, which extracts and integrates hierarchical information from both structural and semantic perspectives. Structurally, HyperLLM uses <span class=\"search-hit mathjax\">LLMs</span> to generate multi-level classification tags with hierarchical parent-child relationships for each item. Then, tag-item and user-item interactions are jointly learned and aligned through contrastive learning, thereby providing the model with clear hierarchical information. Semantically, HyperLLM introduces a novel meta-optimized strategy to extract hierarchical information from semantic embeddings and bridge the gap between the semantic and collaborative spaces for seamless integration. Extensive experiments show that HyperLLM significantly outperforms recommender systems based on hyperbolic space and <span class=\"search-hit mathjax\">LLMs</span>, achieving performance improvements of over 40%. Furthermore, HyperLLM not only improves recommender performance but also enhances training stability, highlighting the critical role of hierarchical information in recommender systems.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05694v1-abstract-full').style.display = 'none'; document.getElementById('2504.05694v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05693\">arXiv:2504.05693</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05693\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05693\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        STRIVE: A Think &amp; Improve Approach with Iterative Refinement for Enhancing Question Quality Estimation\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Deroy%2C+A\">Aniket Deroy</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Maity%2C+S\">Subhankar Maity</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05693v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;propose a novel methodology called STRIVE (Structured Thinking and Refinement with multiLLMs for Improving Verified Question Estimation) using a series of Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) for automatic question evaluation. This approach aims to improve the accuracy and depth of question quality assessment, ultimately supporting diverse learners and enhancing edu&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05693v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05693v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05693v1-abstract-full\" style=\"display: none;\">\n",
      "        Automatically assessing question quality is crucial for educators as it saves time, ensures consistency, and provides immediate feedback for refining teaching materials. We propose a novel methodology called STRIVE (Structured Thinking and Refinement with multiLLMs for Improving Verified Question Estimation) using a series of Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) for automatic question evaluation. This approach aims to improve the accuracy and depth of question quality assessment, ultimately supporting diverse learners and enhancing educational practices. The method estimates question quality in an automated manner by generating multiple evaluations based on the strengths and weaknesses of the provided question and then choosing the best solution generated by the <span class=\"search-hit mathjax\">LLM</span>. Then the process is improved by iterative review and response with another <span class=\"search-hit mathjax\">LLM</span> until the evaluation metric values converge. This sophisticated method of evaluating question quality improves the estimation of question quality by automating the task of question quality evaluation. Correlation scores show that using this proposed method helps to improve correlation with human judgments compared to the baseline method. Error analysis shows that metrics like relevance and appropriateness improve significantly relative to human judgments by using STRIVE.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05693v1-abstract-full').style.display = 'none'; document.getElementById('2504.05693v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">5 pages, 6 figures</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05689\">arXiv:2504.05689</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05689\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05689\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Cryptography and Security\">cs.CR</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Separator Injection Attack: Uncovering Dialogue Biases in Large Language Models Caused by Role Separators\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Li%2C+X\">Xitao Li</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+H\">Haijun Wang</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wu%2C+J\">Jiang Wu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+T\">Ting Liu</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05689v1-abstract-short\" style=\"display: inline;\">\n",
      "        Conversational large language models (<span class=\"search-hit mathjax\">LLMs</span>) have gained widespread attention due to their instruction-following capabilities. To ensure conversational <span class=\"search-hit mathjax\">LLMs</span> follow instructions, role separators are employed to distinguish between different participants in a conversation. However, incorporating role separators introduces&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05689v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05689v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05689v1-abstract-full\" style=\"display: none;\">\n",
      "        Conversational large language models (<span class=\"search-hit mathjax\">LLMs</span>) have gained widespread attention due to their instruction-following capabilities. To ensure conversational <span class=\"search-hit mathjax\">LLMs</span> follow instructions, role separators are employed to distinguish between different participants in a conversation. However, incorporating role separators introduces potential vulnerabilities. Misusing roles can lead to prompt injection attacks, which can easily misalign the model&#39;s behavior with the user&#39;s intentions, raising significant security concerns. Although various prompt injection attacks have been proposed, recent research has largely overlooked the impact of role separators on safety. This highlights the critical need to thoroughly understand the systemic weaknesses in dialogue systems caused by role separators. This paper identifies modeling weaknesses caused by role separators. Specifically, we observe a strong positional bias associated with role separators, which is inherent in the format of dialogue modeling and can be triggered by the insertion of role separators. We further develop the Separators Injection Attack (SIA), a new orthometric attack based on role separators. The experiment results show that SIA is efficient and extensive in manipulating model behavior with an average gain of 18.2% for manual methods and enhances the attack success rate to 100% with automatic methods.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05689v1-abstract-full').style.display = 'none'; document.getElementById('2504.05689v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05683\">arXiv:2504.05683</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05683\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05683\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Towards Smarter Hiring: Are Zero-Shot and Few-Shot Pre-trained <span class=\"search-hit mathjax\">LLMs</span> Ready for HR Spoken Interview Transcript Analysis?\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Maity%2C+S\">Subhankar Maity</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Deroy%2C+A\">Aniket Deroy</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Sarkar%2C+S\">Sudeshna Sarkar</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05683v1-abstract-short\" style=\"display: inline;\">\n",
      "        This research paper presents a comprehensive analysis of the performance of prominent pre-trained large language models (<span class=\"search-hit mathjax\">LLMs</span>), including GPT-4 Turbo, GPT-3.5 Turbo, text-davinci-003, text-babbage-001, text-curie-001, text-ada-001, llama-2-7b-chat, llama-2-13b-chat, and llama-2-70b-chat, in comparison to expert human evaluators in providing scores, identifyi&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05683v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05683v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05683v1-abstract-full\" style=\"display: none;\">\n",
      "        This research paper presents a comprehensive analysis of the performance of prominent pre-trained large language models (<span class=\"search-hit mathjax\">LLMs</span>), including GPT-4 Turbo, GPT-3.5 Turbo, text-davinci-003, text-babbage-001, text-curie-001, text-ada-001, llama-2-7b-chat, llama-2-13b-chat, and llama-2-70b-chat, in comparison to expert human evaluators in providing scores, identifying errors, and offering feedback and improvement suggestions to candidates during mock HR (Human Resources) interviews. We introduce a dataset called HURIT (Human Resource Interview Transcripts), which comprises 3,890 HR interview transcripts sourced from real-world HR interview scenarios. Our findings reveal that pre-trained <span class=\"search-hit mathjax\">LLMs</span>, particularly GPT-4 Turbo and GPT-3.5 Turbo, exhibit commendable performance and are capable of producing evaluations comparable to those of expert human evaluators. Although these <span class=\"search-hit mathjax\">LLMs</span> demonstrate proficiency in providing scores comparable to human experts in terms of human evaluation metrics, they frequently fail to identify errors and offer specific actionable advice for candidate performance improvement in HR interviews. Our research suggests that the current state-of-the-art pre-trained <span class=\"search-hit mathjax\">LLMs</span> are not fully conducive for automatic deployment in an HR interview assessment. Instead, our findings advocate for a human-in-the-loop approach, to incorporate manual checks for inconsistencies and provisions for improving feedback quality as a more suitable strategy.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05683v1-abstract-full').style.display = 'none'; document.getElementById('2504.05683v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">32 pages, 24 figures</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05682\">arXiv:2504.05682</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05682\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05682\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        On the Suitability of Reinforcement Fine-Tuning to Visual Tasks\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Chen%2C+X\">Xiaxu Chen</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Li%2C+W\">Wei Li</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+C\">Chunxu Liu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Xie%2C+C\">Chi Xie</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Hu%2C+X\">Xiaoyan Hu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Ma%2C+C\">Chengqian Ma</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhu%2C+F\">Feng Zhu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Zhao%2C+R\">Rui Zhao</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05682v1-abstract-short\" style=\"display: inline;\">\n",
      "        Reinforcement Fine-Tuning (RFT) is proved to be greatly valuable for enhancing the reasoning ability of <span class=\"search-hit mathjax\">LLMs</span>. Researchers have been starting to apply RFT to MLLMs, hoping it will also enhance the capabilities of visual understanding. However, these works are at a very early stage and have not examined how suitable RFT actually is for visual tasks. In this wo&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05682v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05682v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05682v1-abstract-full\" style=\"display: none;\">\n",
      "        Reinforcement Fine-Tuning (RFT) is proved to be greatly valuable for enhancing the reasoning ability of <span class=\"search-hit mathjax\">LLMs</span>. Researchers have been starting to apply RFT to MLLMs, hoping it will also enhance the capabilities of visual understanding. However, these works are at a very early stage and have not examined how suitable RFT actually is for visual tasks. In this work, we endeavor to understand the suitabilities and limitations of RFT for visual tasks, through experimental analysis and observations. We start by quantitative comparisons on various tasks, which shows RFT is generally better than SFT on visual tasks. %especially when the number of training samples are limited. To check whether such advantages are brought up by the reasoning process, we design a new reward that encourages the model to ``think&#39;&#39; more, whose results show more thinking can be beneficial for complicated tasks but harmful for simple tasks. We hope this study can provide more insight for the rapid advancements on this topic.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05682v1-abstract-full').style.display = 'none'; document.getElementById('2504.05682v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05673\">arXiv:2504.05673</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05673\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05673\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        VC-<span class=\"search-hit mathjax\">LLM</span>: Automated Advertisement Video Creation from Raw Footage using Multi-modal <span class=\"search-hit mathjax\">LLMs</span>\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Qian%2C+D\">Dongjun Qian</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Su%2C+K\">Kai Su</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Tan%2C+Y\">Yiming Tan</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Diao%2C+Q\">Qishuai Diao</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wu%2C+X\">Xian Wu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+C\">Chang Liu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Peng%2C+B\">Bingyue Peng</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Yuan%2C+Z\">Zehuan Yuan</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05673v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;of creative ability. It is usually challenging to create many different video contents for the same product, and manual efficiency is often low. In this paper, we present VC-<span class=\"search-hit mathjax\">LLM</span>, a framework powered by Large Language Models for the automatic creation of high-quality short-form advertisement videos. Our approach leverages high-resolution spatial input and low&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05673v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05673v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05673v1-abstract-full\" style=\"display: none;\">\n",
      "        As short videos have risen in popularity, the role of video content in advertising has become increasingly significant. Typically, advertisers record a large amount of raw footage about the product and then create numerous different short-form advertisement videos based on this raw footage. Creating such videos mainly involves editing raw footage and writing advertisement scripts, which requires a certain level of creative ability. It is usually challenging to create many different video contents for the same product, and manual efficiency is often low. In this paper, we present VC-<span class=\"search-hit mathjax\">LLM</span>, a framework powered by Large Language Models for the automatic creation of high-quality short-form advertisement videos. Our approach leverages high-resolution spatial input and low-resolution temporal input to represent video clips more effectively, capturing both fine-grained visual details and broader temporal dynamics. In addition, during training, we incorporate supplementary information generated by rewriting the ground truth text, ensuring that all key output information can be directly traced back to the input, thereby reducing model hallucinations. We also designed a benchmark to evaluate the quality of the created videos. Experiments show that VC-<span class=\"search-hit mathjax\">LLM</span> based on GPT-4o can produce videos comparable to those created by humans. Furthermore, we collected numerous high-quality short advertisement videos to create a pre-training dataset and manually cleaned a portion of the data to construct a high-quality fine-tuning dataset. Experiments indicate that, on the benchmark, the VC-<span class=\"search-hit mathjax\">LLM</span> based on fine-tuned <span class=\"search-hit mathjax\">LLM</span> can produce videos with superior narrative logic compared to those created by the VC-<span class=\"search-hit mathjax\">LLM</span> based on GPT-4o.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05673v1-abstract-full').style.display = 'none'; document.getElementById('2504.05673v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 8 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05652\">arXiv:2504.05652</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05652\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05652\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Cryptography and Security\">cs.CR</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Sugar-Coated Poison: Benign Generation Unlocks <span class=\"search-hit mathjax\">LLM</span> Jailbreaking\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Wu%2C+Y\">Yu-Hang Wu</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Xiong%2C+Y\">Yu-Jie Xiong</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Jie-Zhang\"> Jie-Zhang</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05652v1-abstract-short\" style=\"display: inline;\">\n",
      "        Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) have become increasingly integral to a wide range of applications. However, they still remain the threat of jailbreak attacks, where attackers manipulate designed prompts to make the models elicit malicious outputs. Analyzing jailbreak methods can help us delve into the weakness of&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05652v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05652v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05652v1-abstract-full\" style=\"display: none;\">\n",
      "        Large Language Models (<span class=\"search-hit mathjax\">LLMs</span>) have become increasingly integral to a wide range of applications. However, they still remain the threat of jailbreak attacks, where attackers manipulate designed prompts to make the models elicit malicious outputs. Analyzing jailbreak methods can help us delve into the weakness of <span class=\"search-hit mathjax\">LLMs</span> and improve it. In this paper, We reveal a vulnerability in large language models (<span class=\"search-hit mathjax\">LLMs</span>), which we term Defense Threshold Decay (DTD), by analyzing the attention weights of the model&#39;s output on input and subsequent output on prior output: as the model generates substantial benign content, its attention weights shift from the input to prior output, making it more susceptible to jailbreak attacks. To demonstrate the exploitability of DTD, we propose a novel jailbreak attack method, Sugar-Coated Poison (SCP), which induces the model to generate substantial benign content through benign input and adversarial reasoning, subsequently producing malicious content. To mitigate such attacks, we introduce a simple yet effective defense strategy, POSD, which significantly reduces jailbreak success rates while preserving the model&#39;s generalization capabilities.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05652v1-abstract-full').style.display = 'none'; document.getElementById('2504.05652v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 7 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05642\">arXiv:2504.05642</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05642\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05642\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Leveraging Prompt-Tuning for Bengali Grammatical Error Explanation Using Large Language Models\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Maity%2C+S\">Subhankar Maity</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Deroy%2C+A\">Aniket Deroy</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05642v1-abstract-short\" style=\"display: inline;\">\n",
      "        We propose a novel three-step prompt-tuning method for Bengali Grammatical Error Explanation (BGEE) using state-of-the-art large language models (<span class=\"search-hit mathjax\">LLMs</span>) such as GPT-4, GPT-3.5 Turbo, and Llama-2-70b. Our approach involves identifying and categorizing grammatical errors in Bengali sentences, generating corrected versions of the sentences, and providing natural&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05642v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05642v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05642v1-abstract-full\" style=\"display: none;\">\n",
      "        We propose a novel three-step prompt-tuning method for Bengali Grammatical Error Explanation (BGEE) using state-of-the-art large language models (<span class=\"search-hit mathjax\">LLMs</span>) such as GPT-4, GPT-3.5 Turbo, and Llama-2-70b. Our approach involves identifying and categorizing grammatical errors in Bengali sentences, generating corrected versions of the sentences, and providing natural language explanations for each identified error. We evaluate the performance of our BGEE system using both automated evaluation metrics and human evaluation conducted by experienced Bengali language experts. Our proposed prompt-tuning approach shows that GPT-4, the best performing <span class=\"search-hit mathjax\">LLM</span>, surpasses the baseline model in automated evaluation metrics, with a 5.26% improvement in F1 score and a 6.95% improvement in exact match. Furthermore, compared to the previous baseline, GPT-4 demonstrates a decrease of 25.51% in wrong error type and a decrease of 26.27% in wrong error explanation. However, the results still lag behind the human baseline.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05642v1-abstract-full').style.display = 'none'; document.getElementById('2504.05642v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 7 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">9 pages, 2 figures</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05638\">arXiv:2504.05638</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05638\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05638\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Distributed, Parallel, and Cluster Computing\">cs.DC</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "        \n",
      "          <div class=\"is-inline-block\" style=\"margin-left: 0.5rem\">\n",
      "            <div class=\"tags has-addons\">\n",
      "              <span class=\"tag is-dark is-size-7\">doi</span>\n",
      "              <span class=\"tag is-light is-size-7\"><a class=\"\" href=\"https://doi.org/10.1145/3721146.3721946\">10.1145/3721146.3721946 <i class=\"fa fa-external-link\" aria-hidden=\"true\"></i></a></span>\n",
      "            </div>\n",
      "          </div>\n",
      "        \n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        TAGC: Optimizing Gradient Communication in Distributed Transformer Training\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Polyakov%2C+I\">Igor Polyakov</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Dukhanov%2C+A\">Alexey Dukhanov</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Spirin%2C+E\">Egor Spirin</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05638v1-abstract-short\" style=\"display: inline;\">\n",
      "        The increasing complexity of large language models (<span class=\"search-hit mathjax\">LLMs</span>) necessitates efficient training strategies to mitigate the high computational costs associated with distributed training. A significant bottleneck in this process is gradient synchronization across multiple GPUs, particularly in the zero-redundancy parallelism mode. In this paper, we introduce Transfo&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05638v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05638v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05638v1-abstract-full\" style=\"display: none;\">\n",
      "        The increasing complexity of large language models (<span class=\"search-hit mathjax\">LLMs</span>) necessitates efficient training strategies to mitigate the high computational costs associated with distributed training. A significant bottleneck in this process is gradient synchronization across multiple GPUs, particularly in the zero-redundancy parallelism mode. In this paper, we introduce Transformer-Aware Gradient Compression (TAGC), an optimized gradient compression algorithm designed specifically for transformer-based models. TAGC extends the lossless homomorphic compression method by adapting it for sharded models and incorporating transformer-specific optimizations, such as layer-selective compression and dynamic sparsification. Our experimental results demonstrate that TAGC accelerates training by up to 15% compared to the standard Fully Sharded Data Parallel (FSDP) approach, with minimal impact on model quality. We integrate TAGC into the PyTorch FSDP framework, the implementation is publicly available at https://github.com/ipolyakov/TAGC.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05638v1-abstract-full').style.display = 'none'; document.getElementById('2504.05638v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 7 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "      <p class=\"comments is-size-7\">\n",
      "        \n",
      "\n",
      "        \n",
      "\n",
      "        \n",
      "          <span class=\"has-text-black-bis has-text-weight-semibold\">ACM Class:</span>\n",
      "          I.2.6; C.2.4; I.2.11\n",
      "        \n",
      "      </p>\n",
      "    \n",
      "\n",
      "    \n",
      "      <p class=\"comments is-size-7\">\n",
      "        <span class=\"has-text-black-bis has-text-weight-semibold\">Journal ref:</span>\n",
      "        EuroMLSys &#39;25: Proceedings of the 5th Workshop on Machine Learning and Systems. 2025. 254-260\n",
      "      </p>\n",
      "    \n",
      "  </li>\n",
      "\n",
      "  <li class=\"arxiv-result\">\n",
      "    <div class=\"is-marginless\">\n",
      "      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2504.05632\">arXiv:2504.05632</a>\n",
      "        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2504.05632\">pdf</a>, <a href=\"https://arxiv.org/format/2504.05632\">other</a>]&nbsp;</span>\n",
      "      </p>\n",
      "      <div class=\"tags is-inline-block\">\n",
      "        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\n",
      "        \n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\n",
      "          \n",
      "            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\n",
      "          \n",
      "        </div>\n",
      "      \n",
      "    </div>\n",
      "    \n",
      "    <p class=\"title is-5 mathjax\">\n",
      "      \n",
      "        Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning\n",
      "      \n",
      "    </p>\n",
      "    <p class=\"authors\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Kabra%2C+S\">Sanchit Kabra</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Jha%2C+A\">Akshita Jha</a>, \n",
      "      \n",
      "      <a href=\"/search/?searchtype=author&amp;query=Reddy%2C+C\">Chandan Reddy</a>\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"abstract mathjax\">\n",
      "      <span class=\"search-hit\">Abstract</span>:\n",
      "      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2504.05632v1-abstract-short\" style=\"display: inline;\">\n",
      "        &hellip;can mitigate harmful stereotypical responses, especially those arising due to shallow or flawed reasoning. We conduct a comprehensive evaluation of multiple open-source <span class=\"search-hit mathjax\">LLMs</span>, and find that larger models with stronger reasoning abilities exhibit substantially lower stereotypical bias on existing fairness benchmarks. Building on this insight, we introduce ReGi&hellip;\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05632v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05632v1-abstract-short').style.display = 'none';\">&#9661; More</a>\n",
      "      </span>\n",
      "      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2504.05632v1-abstract-full\" style=\"display: none;\">\n",
      "        Recent advances in large-scale generative language models have shown that reasoning capabilities can significantly improve model performance across a variety of tasks. However, the impact of reasoning on a model&#39;s ability to mitigate stereotypical responses remains largely underexplored. In this work, we investigate the crucial relationship between a model&#39;s reasoning ability and fairness, and ask whether improved reasoning capabilities can mitigate harmful stereotypical responses, especially those arising due to shallow or flawed reasoning. We conduct a comprehensive evaluation of multiple open-source <span class=\"search-hit mathjax\">LLMs</span>, and find that larger models with stronger reasoning abilities exhibit substantially lower stereotypical bias on existing fairness benchmarks. Building on this insight, we introduce ReGiFT -- Reasoning Guided Fine-Tuning, a novel approach that extracts structured reasoning traces from advanced reasoning models and infuses them into models that lack such capabilities. We use only general-purpose reasoning and do not require any fairness-specific supervision for bias mitigation. Notably, we see that models fine-tuned using ReGiFT not only improve fairness relative to their non-reasoning counterparts but also outperform advanced reasoning models on fairness benchmarks. We also analyze how variations in the correctness of the reasoning traces and their length influence model fairness and their overall performance. Our findings highlight that enhancing reasoning capabilities is an effective, fairness-agnostic strategy for mitigating stereotypical bias caused by reasoning flaws.\n",
      "        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById('2504.05632v1-abstract-full').style.display = 'none'; document.getElementById('2504.05632v1-abstract-short').style.display = 'inline';\">&#9651; Less</a>\n",
      "      </span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 7 April, 2025; \n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> April 2025.\n",
      "      \n",
      "    </p>\n",
      "    \n",
      "    <p class=\"comments is-size-7\">\n",
      "      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\n",
      "      <span class=\"has-text-grey-dark mathjax\">17 pages</span>\n",
      "    </p>\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "  </li>\n",
      "\n",
      "</ol>\n",
      "\n",
      "\n",
      "  <nav class=\"pagination is-small is-centered breathe-horizontal\" role=\"navigation\" aria-label=\"pagination\">\n",
      "    \n",
      "    <a href=\"\"\n",
      "      class=\"pagination-previous is-invisible\">Previous\n",
      "    </a>\n",
      "    \n",
      "    \n",
      "      <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=50\"\n",
      "        class=\"pagination-next\" >Next\n",
      "      </a>\n",
      "    \n",
      "    <ul class=\"pagination-list\">\n",
      "\n",
      "      <li>\n",
      "        <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=0\"\n",
      "          class=\"pagination-link is-current\"\n",
      "          aria-label=\"Goto page 1\">1\n",
      "        </a>\n",
      "      </li>\n",
      "\n",
      "      \n",
      "                                     \n",
      "          \n",
      "          <li>\n",
      "            <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=50\"\n",
      "              class=\"pagination-link \"\n",
      "              aria-label=\"Page 2\"\n",
      "              aria-current=\"page\">2\n",
      "            </a>\n",
      "          </li>\n",
      "          \n",
      "          <li>\n",
      "            <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=100\"\n",
      "              class=\"pagination-link \"\n",
      "              aria-label=\"Page 3\"\n",
      "              aria-current=\"page\">3\n",
      "            </a>\n",
      "          </li>\n",
      "          \n",
      "          <li>\n",
      "            <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=150\"\n",
      "              class=\"pagination-link \"\n",
      "              aria-label=\"Page 4\"\n",
      "              aria-current=\"page\">4\n",
      "            </a>\n",
      "          </li>\n",
      "          \n",
      "          <li>\n",
      "            <a href=\"/search/?query=LLM&amp;searchtype=all&amp;source=header&amp;start=200\"\n",
      "              class=\"pagination-link \"\n",
      "              aria-label=\"Page 5\"\n",
      "              aria-current=\"page\">5\n",
      "            </a>\n",
      "          </li>\n",
      "          \n",
      "          <li><span class=\"pagination-ellipsis\">&hellip;</span></li>\n",
      "        \n",
      "      \n",
      "    </ul>\n",
      "  </nav>\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "      <div class=\"is-hidden-tablet\">\n",
      "        <!-- feedback for mobile only -->\n",
      "        <span class=\"help\" style=\"display: inline-block;\"><a href=\"https://github.com/arXiv/arxiv-search/releases\">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>\n",
      "      </div>\n",
      "    </div>\n",
      "\n",
      "  </main>\n",
      "  <footer>\n",
      "    \n",
      "    <div class=\"columns is-desktop\" role=\"navigation\" aria-label=\"Secondary\">\n",
      "  <!-- MetaColumn 1 -->\n",
      "  <div class=\"column\">\n",
      "    <div class=\"columns\">\n",
      "      <div class=\"column\">\n",
      "        <ul class=\"nav-spaced\">\n",
      "          <li><a href=\"https://info.arxiv.org/about\">About</a></li>\n",
      "          <li><a href=\"https://info.arxiv.org/help\">Help</a></li>\n",
      "        </ul>\n",
      "      </div>\n",
      "      <div class=\"column\">\n",
      "        <ul class=\"nav-spaced\">\n",
      "          <li>\n",
      "            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\"/></svg>\n",
      "            <a href=\"https://info.arxiv.org/help/contact.html\"> Contact</a>\n",
      "          </li>\n",
      "          <li>\n",
      "            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d=\"M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z\"/></svg>\n",
      "            <a href=\"https://info.arxiv.org/help/subscribe\"> Subscribe</a>\n",
      "          </li>\n",
      "        </ul>\n",
      "      </div>\n",
      "    </div>\n",
      "  </div> <!-- end MetaColumn 1 -->\n",
      "  <!-- MetaColumn 2 -->\n",
      "  <div class=\"column\">\n",
      "    <div class=\"columns\">\n",
      "      <div class=\"column\">\n",
      "        <ul class=\"nav-spaced\">\n",
      "          <li><a href=\"https://info.arxiv.org/help/license/index.html\">Copyright</a></li>\n",
      "          <li><a href=\"https://info.arxiv.org/help/policies/privacy_policy.html\">Privacy Policy</a></li>\n",
      "        </ul>\n",
      "      </div>\n",
      "      <div class=\"column sorry-app-links\">\n",
      "        <ul class=\"nav-spaced\">\n",
      "          <li><a href=\"https://info.arxiv.org/help/web_accessibility.html\">Web Accessibility Assistance</a></li>\n",
      "          <li>\n",
      "            <p class=\"help\">\n",
      "              <a class=\"a11y-main-link\" href=\"https://status.arxiv.org\" target=\"_blank\">arXiv Operational Status <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\" class=\"icon filter-dark_grey\" role=\"presentation\"><path d=\"M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z\"/></svg></a><br>\n",
      "              Get status notifications via\n",
      "              <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/email/new\" target=\"_blank\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\"/></svg>email</a>\n",
      "              or <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/slack/new\" target=\"_blank\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\" class=\"icon filter-black\" role=\"presentation\"><path d=\"M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z\"/></svg>slack</a>\n",
      "            </p>\n",
      "          </li>\n",
      "        </ul>\n",
      "      </div>\n",
      "    </div>\n",
      "  </div> <!-- end MetaColumn 2 -->\n",
      "</div>\n",
      "    \n",
      "  </footer>\n",
      "  <script src=\"https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js\"></script>\n",
      "  </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print (response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
